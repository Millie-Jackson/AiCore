{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 486>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=482'>483</a>\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownloadImage(\u001b[39mself\u001b[39m, j, data\u001b[39m.\u001b[39mrecipeName)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=483'>484</a>\u001b[0m                 data\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m                \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=485'>486</a>\u001b[0m scraper\u001b[39m.\u001b[39;49mintitialize(scraper, \u001b[39m'\u001b[39;49m\u001b[39mhttps://www.pickuplimes.com\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlemons\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.intitialize\u001b[1;34m(self, url, searchTerm, delay)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=66'>67</a>\u001b[0m global_ids \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39mgetUniqueID(scraper, \u001b[39m'\u001b[39m\u001b[39mhttps://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=68'>69</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetURL(url) \u001b[39m# Have to start somewhere\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=69'>70</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=70'>71</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloseSession()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=90'>91</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetAllRecipePages(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=91'>92</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetRecipes(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=92'>93</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcycleRecipeLinks(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=93'>94</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloseSession()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.cycleRecipeLinks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mrecipeLinks:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=97'>98</a>\u001b[0m     data\u001b[39m.\u001b[39mcurrentURL \u001b[39m=\u001b[39m i\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=98'>99</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmakeImage(\u001b[39mself\u001b[39;49m, data\u001b[39m.\u001b[39;49mcurrentURL)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.makeImage\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=466'>467</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmakeImage\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=467'>468</a>\u001b[0m     \u001b[39m'''Retrieves the ID of each image using 'getRecipeDetails()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=468'>469</a>\u001b[0m \u001b[39m    Removes all unecissary elements from the ID string to create a file name\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=469'>470</a>\u001b[0m \u001b[39m    Pass the file name to 'downloadImages() to create a file'''\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=471'>472</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetRecipeDetails(\u001b[39mself\u001b[39;49m, url)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=473'>474</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mrecipeDetails[\u001b[39m'\u001b[39m\u001b[39mImages\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=474'>475</a>\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m i:\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.exceptionHandling.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=75'>76</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func) \u001b[39m# maintains introspection\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=76'>77</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=77'>78</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=78'>79</a>\u001b[0m         func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=79'>80</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m NoSuchElementException:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=80'>81</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Exception: Element Not Found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.getRecipeDetails\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=351'>352</a>\u001b[0m \u001b[39m@exceptionHandling\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=352'>353</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetRecipeDetails\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=353'>354</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetURL(url)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=355'>356</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeName()  \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=356'>357</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeTags()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.getURL\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=100'>101</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetURL\u001b[39m(url):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=101'>102</a>\u001b[0m     \u001b[39m'''Navigates to a website using a url passed as a perameter.'''\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=102'>103</a>\u001b[0m     driver\u001b[39m.\u001b[39;49mget(url)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:437\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=432'>433</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=433'>434</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=434'>435</a>\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=435'>436</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=436'>437</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:423\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=419'>420</a>\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=421'>422</a>\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=422'>423</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=424'>425</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:333\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=330'>331</a>\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=331'>332</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=332'>333</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:355\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=351'>352</a>\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=354'>355</a>\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=355'>356</a>\u001b[0m     statuscode \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/remote_connection.py?line=356'>357</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=74'>75</a>\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=75'>76</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=76'>77</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=77'>78</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=78'>79</a>\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=79'>80</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=166'>167</a>\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=167'>168</a>\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/request.py?line=169'>170</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/poolmanager.py?line=373'>374</a>\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/poolmanager.py?line=374'>375</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/poolmanager.py?line=375'>376</a>\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/poolmanager.py?line=377'>378</a>\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/poolmanager.py?line=378'>379</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=699'>700</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=701'>702</a>\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=702'>703</a>\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=703'>704</a>\u001b[0m     conn,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=704'>705</a>\u001b[0m     method,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=705'>706</a>\u001b[0m     url,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=706'>707</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=707'>708</a>\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=708'>709</a>\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=709'>710</a>\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=710'>711</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=712'>713</a>\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=713'>714</a>\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=714'>715</a>\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=715'>716</a>\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=716'>717</a>\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=443'>444</a>\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=444'>445</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=445'>446</a>\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=446'>447</a>\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=447'>448</a>\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=448'>449</a>\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=449'>450</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=450'>451</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=440'>441</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=441'>442</a>\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=442'>443</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=443'>444</a>\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=444'>445</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=445'>446</a>\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=446'>447</a>\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=447'>448</a>\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/urllib3/connectionpool.py?line=448'>449</a>\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\http\\client.py:1371\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=1368'>1369</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=1369'>1370</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=1370'>1371</a>\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=1371'>1372</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=1372'>1373</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\http\\client.py:319\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=316'>317</a>\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=317'>318</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=318'>319</a>\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=319'>320</a>\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=320'>321</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\http\\client.py:280\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=278'>279</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=279'>280</a>\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=280'>281</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/http/client.py?line=281'>282</a>\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/socket.py?line=701'>702</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/socket.py?line=702'>703</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/socket.py?line=703'>704</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/socket.py?line=704'>705</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/socket.py?line=705'>706</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import functools # used to maintain introspection on decorators\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import uuid # used to create a unique 'computer' id for each recipe\n",
    "import json # used to store the scraped details\n",
    "import os\n",
    "\n",
    "from uuid import UUID # used to create a unique id for each recipe\n",
    "from json import JSONEncoder # used to convert the UUID into a writable format\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "#from decorators import noSuchElementException\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class data:\n",
    "\n",
    "    articles = [] # Used to make a list of recipes\n",
    "    button = None # Used to interact with various button elements\n",
    "    container = None # Used to store various container elements\n",
    "    count = 0 # Used in the creation of image filenames\n",
    "    currentURL = \"\" # Used to store various urls \n",
    "    pages = [] # Used to append a list with pages links\n",
    "    recipeDetails = {} # Used to store all the scraped recipe details\n",
    "    recipeDirectory = \"\" # Used to create modified folder names\n",
    "    recipeLinks = [] # Used to store recipe links\n",
    "    recipeName = \"\" # Stores the recipe name\n",
    "    searchbar = None # Used to interact with search bar\n",
    "    source = \"\" # Used to get page source code\n",
    "    tag = None # Used to store various tag elements\n",
    "    title = \"\" # Used to get the title\n",
    "    totalPages = [] # Stores a list of pages\n",
    "\n",
    "    # Scraped Information\n",
    "    allergens = \"\" # Used to store scraped allergens\n",
    "    alternatives = \"\" #Used to store scraped alternatives\n",
    "    description = \"\" # Used to store the scraped description of the recipe\n",
    "    freeFrom = \"\" # Used to store the scraped free from information\n",
    "    imageLinks = [] # Used to scrape all of a recipes image links\n",
    "    ingredients = \"\" # Used to store the scraped ingredients\n",
    "    instructions = \"\" # Used to store scraped instructions\n",
    "    mainPhoto = None # Used to store main photo link\n",
    "    name = \"\" # Used to store scraped recipe name\n",
    "    notes = \"\" # Used to store scraped recipe notes\n",
    "    recipeTags = \"\" # Used to store scraped recipe tags\n",
    "    storage = \"\" # Used to store scraped storage instructions\n",
    "    timeCook = \"\" # Used to store scraped cook time\n",
    "    timePrep = \"\" # Used to store scraped recipe  prep time \n",
    "    timeTotal = \"\" # Used to store scraped total time it takes to make the recipe\n",
    "\n",
    "class scraper:\n",
    "    def intitialize(self, url, searchTerm, delay):\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "    \n",
    "        self.getURL(url) # Have to start somewhere\n",
    "        self.run(self)\n",
    "        self.closeSession() # Have to end somewhere\n",
    "    \n",
    "    # DECORATORS\n",
    "\n",
    "    def exceptionHandling(func):\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                func(*args, **kwargs)\n",
    "            except NoSuchElementException:\n",
    "                print(f\"{func.__name__} Exception: Element Not Found\")\n",
    "            except TimeoutException:\n",
    "                print(f\"{func.__name__} Exception: Timeout\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        #self.acceptCookies()\n",
    "        data.currentURL = self.findRecipeList(self)\n",
    "        self.getAllRecipePages(self, data.currentURL)\n",
    "        self.getRecipes(self, data.currentURL)\n",
    "        self.cycleRecipeLinks(self)\n",
    "        self.closeSession()   \n",
    "\n",
    "    def cycleRecipeLinks(self):\n",
    "        for i in data.recipeLinks:\n",
    "            data.currentURL = i\n",
    "            self.makeImage(self, data.currentURL)\n",
    "\n",
    "    def getURL(url):\n",
    "        '''Navigates to a website using a url passed as a perameter.'''\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle():\n",
    "        '''Fetches the title and prints it to screen.'''\n",
    "        data.title = driver.title\n",
    "\n",
    "    def closeSession():\n",
    "        '''Closes the driver'''\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode():\n",
    "        '''Fetches source code for the page.'''\n",
    "        data.source = driver.page_source\n",
    "\n",
    "    @exceptionHandling\n",
    "    def search(self, searchTerm):\n",
    "        '''Finds search bar, types in the search term which it takes as a perameter and clicks to navigate to the next page.'''\n",
    "        button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "        button.click()\n",
    "\n",
    "        self.findSearchbar(self, searchTerm)\n",
    "\n",
    "    def searchbarTextAndClick(searchTerm):\n",
    "        try:\n",
    "            data.searchbar.send_keys(searchTerm)\n",
    "            data.searchbar.send_keys(Keys.RETURN) # Return = Enter\n",
    "        except:\n",
    "            print(\"Exception: No search term input\")\n",
    "    \n",
    "    @exceptionHandling\n",
    "    def findSearchbar(self, searchTerm):\n",
    "\n",
    "        data.searchbar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "        self.searchbarTextAndClick(searchTerm)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def home():\n",
    "        '''Finds the title and clicks it.'''\n",
    "        title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "        title.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def findRecipeList(self):\n",
    "        '''Finds the recipe tab and clicks it.'''\n",
    "        data.button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "        data.button.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def acceptCookies():\n",
    "        '''Finds the accept cookies button and clicks it.'''\n",
    "        data.button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "        data.button.click()\n",
    "    \n",
    "    def getRecipes(self, url):\n",
    "        '''Finds the recipe container and puts all the recipes in a list.'''\n",
    "\n",
    "        self.getRecipeContainer()\n",
    "        self.makeRecipeList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeContainer():\n",
    "        data.container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='index-item-container']/div/div[2]/ul\"))) \n",
    "\n",
    "    def makeRecipeList():\n",
    "        data.articles = data.container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for i in data.articles:\n",
    "            data.tag = i.find_element(By.TAG_NAME, 'a')\n",
    "            data.recipeLinks.append(data.tag.get_attribute('href'))\n",
    "\n",
    "    def getPageURL():\n",
    "        '''Returns the current page url.'''\n",
    "        data.currentURL =  driver.current_url\n",
    "\n",
    "    def getAllRecipePages(self, url):\n",
    "        '''Navigates to each recipe page by modifying the current url and stores them in a list.'''\n",
    "\n",
    "        self.getTotalPages()\n",
    "        self.getSearchList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getTotalPages():\n",
    "         #totalPages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "        data.totalPages = [1, 2, 3] #temp to shorten runtime\n",
    "\n",
    "    def getSearchList():\n",
    "        for i in data.totalPages:\n",
    "            data.currentURL = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = data.currentURL + url_change\n",
    "            data.pages.append(next_page)\n",
    "\n",
    "    def getUniqueID(self, url):\n",
    "        '''Creates a uuid for each recipe taking a url as a perameter'''\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "    def scrapeName():\n",
    "        try:    \n",
    "            data.name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Name Not Found\")\n",
    "            data.name = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Name\")\n",
    "            data.name = \"N/A\" \n",
    "\n",
    "    def scrapeTags():\n",
    "        try:\n",
    "            data.recipeTags = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Tag Not Found\")\n",
    "            data.recipeTags = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Tag\")\n",
    "            data.recipeTags = \"N/A\"\n",
    "\n",
    "    def scrapeDescription():\n",
    "        try:\n",
    "            data.description = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Description Not Found\")\n",
    "            data.description = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Description\")\n",
    "            data.description = \"N/A\"\n",
    "\n",
    "    def scrapeTotalTime():\n",
    "        try:\n",
    "            data.timeTotal = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Total-Time Not Found\")\n",
    "            data.timeTotal = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Total-Time\")\n",
    "            data.timeTotal = \"N/A\"\n",
    "\n",
    "    def scrapePrepTime():\n",
    "        try:\n",
    "            data.timePrep = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Prep-Time Not Found\")\n",
    "            data.timePrep = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Prep-Time\")\n",
    "            data.timePrep = \"N/A\"\n",
    "\n",
    "    def scrapeCookTime():\n",
    "        try:\n",
    "            data.timeCook = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Cook-Time Not Found\")\n",
    "            data.timeCook = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Cook-Time\")\n",
    "            data.timeCook = \"N/A\" \n",
    "\n",
    "    def scrapeAllergens():\n",
    "        try:\n",
    "            data.allergens = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Allergens Not Found\")\n",
    "            data.allergens = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Allergens\")\n",
    "            data.allergens = \"N/A\"\n",
    "\n",
    "    def scrapeAlternatives():\n",
    "        try: \n",
    "            data.alternatives = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Swap Not Found\")\n",
    "            data.alternatives = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Swap\")\n",
    "            data.alternatives = \"N/A\"\n",
    "\n",
    "    def scrapeFreeFrom():\n",
    "        try:\n",
    "            data.freeFrom = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text \n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Free-From Not Found\")\n",
    "            data.freeFrom = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Free-From\")\n",
    "            data.freeFrom = \"N/A\" \n",
    "\n",
    "    def scrapeIngredients():\n",
    "        try:\n",
    "            data.ingredients = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Ingredients Not Found\")\n",
    "            data.ingredients = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Ingredients\")\n",
    "            data.ingredients = \"N/A\"\n",
    "\n",
    "    def scrapeInstructions():\n",
    "        try:\n",
    "            data.instructions = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Directions Not Found\")\n",
    "            data.instructions = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Directions\")\n",
    "            data.instructions = \"N/A\"\n",
    "\n",
    "    def scrapeNotes():\n",
    "        try:\n",
    "            data.notes = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Notes Not Found\")\n",
    "            data.notes = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Notes\")\n",
    "            data.notes = \"N/A\"\n",
    "\n",
    "    def scrapeStorage():\n",
    "        try:\n",
    "            data.storage = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Storage Not Found\")\n",
    "            data.storage = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Storage\")\n",
    "            data.storage = \"N/A\"\n",
    "\n",
    "    def scrapeMainPhoto():\n",
    "        try:\n",
    "            data.mainPhoto = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Main Image Not Found\")\n",
    "            data.mainPhoto = \"N/A\"\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find Main Image\")\n",
    "            data.mainPhoto = \"N/A\"\n",
    "\n",
    "    @exceptionHandling\n",
    "    def scrapeImages():\n",
    "        imageContainer = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        imageList = imageContainer.find_elements(By.XPATH, 'img') # Find the children\n",
    "\n",
    "        for i in imageList:\n",
    "            link = i.get_attribute('src')\n",
    "            data.imageLinks.append(link)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeDetails(self, url):\n",
    "        self.getURL(url)\n",
    "\n",
    "        self.scrapeName()  \n",
    "        self.scrapeTags()\n",
    "        self.scrapeDescription()\n",
    "        self.scrapeTotalTime()\n",
    "        self.scrapePrepTime()\n",
    "        self.scrapeCookTime()\n",
    "        self.scrapeAllergens()\n",
    "        self.scrapeAlternatives()\n",
    "        self.scrapeFreeFrom()\n",
    "        self.scrapeIngredients()\n",
    "        self.scrapeInstructions()\n",
    "        self.scrapeNotes()\n",
    "        self.scrapeStorage()\n",
    "        self.scrapeMainPhoto()\n",
    "        self.scrapeImages()\n",
    "\n",
    "        self.storeDetails(self, url)\n",
    "        self.jsonFile(self)\n",
    "\n",
    "    def storeDetails(self, url):\n",
    "        data.recipeDetails = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        data.recipeDetails['ID'].append(self.getUniqueID(self, url))\n",
    "        data.recipeDetails['Name'].append(data.name)\n",
    "        data.recipeDetails['Photo'].append(data.mainPhoto)\n",
    "        data.recipeDetails['Tags'].append(data.recipeTags)\n",
    "        data.recipeDetails['Description'].append(data.description)\n",
    "        data.recipeDetails['Total Time'].append(data.timeTotal)\n",
    "        data.recipeDetails['Prep Time'].append(data.timePrep)\n",
    "        data.recipeDetails['Cook Time'].append(data.timeCook)\n",
    "        data.recipeDetails['Allergens'].append(data.allergens)\n",
    "        data.recipeDetails['Swaps'].append(data.alternatives)\n",
    "        data.recipeDetails['Free From'].append(data.freeFrom)\n",
    "        data.recipeDetails['Ingredients'].append(data.ingredients)\n",
    "        data.recipeDetails['Directions'].append(data.instructions)\n",
    "        data.recipeDetails['Notes'].append(data.notes)\n",
    "        data.recipeDetails['Storage'].append(data.storage)\n",
    "        data.recipeDetails['Images'].append(data.imageLinks)\n",
    "\n",
    "    def jsonFile(self):\n",
    "        '''Creates a folder called 'raw_data' in the path for the json file to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folder already exists'''\n",
    "\n",
    "        self.makeRaw_DataFolder()\n",
    "\n",
    "        '''Deals with TypeError: Object of type UUID is not JSON serializable by encoding the UUID'''\n",
    "        JSONEncoder_olddefault = JSONEncoder.default\n",
    "        def JSONEncoder_newdefault(self, o):\n",
    "            if isinstance(o, UUID): return str(o)\n",
    "            return JSONEncoder_olddefault(self, o)\n",
    "        JSONEncoder.default = JSONEncoder_newdefault\n",
    "\n",
    "        self.jsonDump()\n",
    "\n",
    "    def makeRaw_DataFolder():\n",
    "        try:\n",
    "            directory = \"raw_data\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Folder already exists: raw_data\")\n",
    "    \n",
    "    def jsonDump():\n",
    "        '''Stores data by writing the 'recipe_details' dictionary to a JSON file called 'data.json' in the folder just created\n",
    "        The dicrionary is converted to a string using str() to deal with 'TypeError: Object of type WebElement is not JSON serializable'''\n",
    "        with open(os.path.join('raw_data', 'data.json'), 'w') as json_file:\n",
    "            json.dump(str(data.recipeDetails), json_file)\n",
    "\n",
    "    def downloadImage(self, url, recipeName):\n",
    "        '''Creates a folder called 'images' and another with the recipe name in the path for the image files to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folders already exists\n",
    "        Adds User-Agent Headers to bypass 403 error\n",
    "        Downloads the images into the folder of that recipe name'''\n",
    "\n",
    "        self.makeImagesFolder()\n",
    "        self.makeRecipeFolder()\n",
    "        \n",
    "        try:\n",
    "            # Adds headers to resolve 403 Fobidden Error\n",
    "            opener=urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            downloadDirectory = \"images/\" + data.recipeDirectory + \"/\"\n",
    "            fileType = '.jpg'\n",
    "            fileName = downloadDirectory + recipeName + fileType\n",
    "            image = urllib.request.urlretrieve(url, fileName)\n",
    "        except:\n",
    "            print(\"Error Downloading Images\")           \n",
    "\n",
    "    def makeImagesFolder():\n",
    "        try:\n",
    "            directory = \"images\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Folder already exists: images\")\n",
    "\n",
    "    def makeRecipeFolder():\n",
    "        try:\n",
    "            data.recipeDirectory = data.recipeName.replace(\".jpg\", \"\").replace(\"0\", \"\").replace(\"1\", \"\").replace(\"2\", \"\").replace(\"3\", \"\").replace(\"4\", \"\").replace(\"5\", \"\").replace(\"6\", \"\").replace(\"7\", \"\").replace(\"8\", \"\").replace(\"9\", \"\")\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images\"\n",
    "            path = os.path.join(parent_dir, data.recipeDirectory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % data.recipeDirectory)\n",
    "        except:\n",
    "            print(\"Folder already exists:\", data.recipeDirectory)\n",
    "\n",
    "    def makeImage(self, url):\n",
    "        '''Retrieves the ID of each image using 'getRecipeDetails()\n",
    "        Removes all unecissary elements from the ID string to create a file name\n",
    "        Pass the file name to 'downloadImages() to create a file'''\n",
    "        \n",
    "        self.getRecipeDetails(self, url)\n",
    "        \n",
    "        for i in data.recipeDetails['Images']:\n",
    "            for j in i:\n",
    "                IDtoName = str(data.recipeDetails['ID']).split()\n",
    "                IDtoName1 = str(IDtoName[0]).replace(\"(\", \"\")\n",
    "                IDtoName2 = str(IDtoName1).replace(\"[\", \"\")\n",
    "                IDtoName3 = str(IDtoName2).replace(\",\", \"\")\n",
    "                IDtoName4 = str(IDtoName3).replace(\"'\", \"\")\n",
    "\n",
    "                data.recipeName = IDtoName4 + \"-\" + str(data.count) + \".jpg\"\n",
    "                self.downloadImage(self, j, data.recipeName)\n",
    "                data.count = data.count + 1                \n",
    "\n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons', 5)\n",
    "#scraper.testFunction(scraper)\n",
    "# IDEALS\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# make a separate main image\n",
    "# counts how many recipes there are on the site\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# bypass login\n",
    "# replace all XPaths with written XPaths\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument\n",
    "# seperate website specific methods from general functioning in a class\n",
    "# make sure all code works with any website so is reusable and genralisable\n",
    "# use the unique id (page url) to stop scraping recipes it has already scraped \n",
    "# have a wait for element function that takes a xpath and a perameter\n",
    "# time each function to optimise run speed\n",
    "# error handeling function? all error hadling is done by one function?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
