{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class scraper:\n",
    "    def intitialize(self, url, search_term):\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "        \n",
    "        self.getURL(url)\n",
    "        #self.getTitle()\n",
    "        #self.acceptCookies()\n",
    "        #self.getAllRecipePages()\n",
    "        #self.getSourceCode()\n",
    "        self.search(search_term)\n",
    "        #time.sleep(3)\n",
    "        #self.home()\n",
    "        #self.findRecipeList()\n",
    "        #self.getRecipes()\n",
    "        #self.getPageURL()\n",
    "        #self.getUniqueID()\n",
    "        #self.getRecipeDetails(self)\n",
    "        #time.sleep(3)\n",
    "\n",
    "        self.closeSession()\n",
    "\n",
    "    def getURL(url):\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle():\n",
    "        print(driver.title)\n",
    "\n",
    "    def closeSession():\n",
    "        time.sleep(3)\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode():\n",
    "        print(driver.page_source)\n",
    "    \n",
    "    def search(search_term):\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "            button.click()\n",
    "            try:\n",
    "                search_bar = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "                try:\n",
    "                    search_bar.send_keys(search_term)\n",
    "                    search_bar.send_keys(Keys.RETURN) # Return = Enter\n",
    "                except:\n",
    "                    print(\"Exception: No search term input\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: No search bar found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Search bar\")\n",
    "\n",
    "    def home():\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "            title.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Title Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Title\")\n",
    "\n",
    "    def findRecipeList():\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "            button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Recipe List Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Recipe List\")\n",
    "\n",
    "    def acceptCookies():\n",
    "        try:\n",
    "            cookie_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "            cookie_button.click()\n",
    "            print(\"Removed Cookies\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exeption: Didnt Find Cookie Button\")\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout: Accept Cookie\")\n",
    "    \n",
    "    def getRecipes():\n",
    "        try:\n",
    "            main = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'index-item-container')))      \n",
    "            articles = []\n",
    "            articles = main.find_elements(By.TAG_NAME, 'li')\n",
    "            print(\"Number of Recipes:\", len(articles))\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Can't Find Recipe List\")\n",
    "        except TimeoutException: \n",
    "            print(\"Exception: Timeout: Can't Find Recipe List\")\n",
    "\n",
    "        for i in articles:\n",
    "            print(\"Recipe:\" , i.text)\n",
    "\n",
    "    def getPageURL():\n",
    "        print(\"URL:\", driver.current_url)\n",
    "\n",
    "    def getAllRecipePages(self):\n",
    "        pages = []\n",
    "        self.getURL('https://www.pickuplimes.com/')\n",
    "        scraper.findRecipeList()\n",
    "        page = [driver.current_url]\n",
    "\n",
    "        try:\n",
    "            #total_pages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "            total_pages = [1, 2, 3, 4, 5] #temp to shorten runtime\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Total Pages Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Couldn't Find Total Pages\")\n",
    "\n",
    "        for i in total_pages:\n",
    "            current_page = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = current_page + url_change\n",
    "            print(next_page)\n",
    "            pages.append(next_page)\n",
    "            print(\"Number of Pages:\", len(pages))\n",
    "\n",
    "    def getUniqueID(self, url):\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def getRecipeDetails(self):\n",
    "        self.getURL('https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "\n",
    "        try:\n",
    "            name = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "            tag = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "            description = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "            time_total = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "            time_prep = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "            time_cook = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "            allergens = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "            swap = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "            free_from = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text  \n",
    "            ingredients = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "            directions = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "            notes = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "            storage = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "            picture_main = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: One Or More Data Entry Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find All Data Entries\")\n",
    "\n",
    "        image_container = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        image_list = image_container.find_elements(By.XPATH, 'img') # Find the children\n",
    "        print(len(image_list))\n",
    "        image_links= []\n",
    "\n",
    "        for i in image_list:\n",
    "            link = i.get_attribute('src')\n",
    "            image_links.append(link)\n",
    "        \n",
    "        recipe_details = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        recipe_details['ID'].append(self.getUniqueID(self, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213'))\n",
    "        recipe_details['Name'].append(name)\n",
    "        recipe_details['Photo'].append(picture_main)\n",
    "        recipe_details['Tags'].append(tag)\n",
    "        recipe_details['Description'].append(description)\n",
    "        recipe_details['Total Time'].append(time_total)\n",
    "        recipe_details['Prep Time'].append(time_prep)\n",
    "        recipe_details['Cook Time'].append(time_cook)\n",
    "        recipe_details['Allergens'].append(allergens)\n",
    "        recipe_details['Swaps'].append(swap)\n",
    "        recipe_details['Free From'].append(free_from)\n",
    "        recipe_details['Ingredients'].append(ingredients)\n",
    "        recipe_details['Directions'].append(directions)\n",
    "        recipe_details['Notes'].append(notes)\n",
    "        recipe_details['Storage'].append(storage)\n",
    "        recipe_details['Images'].append(image_list)\n",
    "\n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons')\n",
    "#global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "#print(global_ids)\n",
    "\n",
    "\n",
    "# IDEALS\n",
    "# store all recipe images in a list\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# counts how many recipes there are\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# bypass login\n",
    "# replace all XPaths with written XPatha\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "print(my_list * 2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4aa49906c49aab2699de75d29353ef6218c1548a647ded36ad1d3c83fbb1a8d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
