{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of ChromeDriver only supports Chrome version 99\nCurrent browser version is 101.0.4951.54 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00CC9943+2595139]\n\tOrdinal0 [0x00C5C9F1+2148849]\n\tOrdinal0 [0x00B54528+1066280]\n\tOrdinal0 [0x00B742C3+1196739]\n\tOrdinal0 [0x00B6FE37+1179191]\n\tOrdinal0 [0x00B6D6F1+1169137]\n\tOrdinal0 [0x00BA0530+1377584]\n\tOrdinal0 [0x00BA018A+1376650]\n\tOrdinal0 [0x00B9B806+1357830]\n\tOrdinal0 [0x00B76086+1204358]\n\tOrdinal0 [0x00B76F96+1208214]\n\tGetHandleVerifier [0x00E6B232+1658114]\n\tGetHandleVerifier [0x00F2312C+2411516]\n\tGetHandleVerifier [0x00D5F261+560433]\n\tGetHandleVerifier [0x00D5E366+556598]\n\tOrdinal0 [0x00C6286B+2173035]\n\tOrdinal0 [0x00C675F8+2192888]\n\tOrdinal0 [0x00C676E5+2193125]\n\tOrdinal0 [0x00C711FC+2232828]\n\tBaseThreadInitThunk [0x75C2FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A4E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebdriver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msupport\u001b[39;00m \u001b[39mimport\u001b[39;00m expected_conditions \u001b[39mas\u001b[39;00m EC\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=19'>20</a>\u001b[0m \u001b[39m#from selenium.webdriver.chrome.options import Options\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=20'>21</a>\u001b[0m \u001b[39m#from webdriver_manager.chrome import ChromeDriverManager\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=22'>23</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=24'>25</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdata\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=25'>26</a>\u001b[0m     articles \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:70\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m service:\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=67'>68</a>\u001b[0m     service \u001b[39m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=69'>70</a>\u001b[0m \u001b[39msuper\u001b[39;49m(WebDriver, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m'\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=70'>71</a>\u001b[0m                                 port, options,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=71'>72</a>\u001b[0m                                 service_args, desired_capabilities,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chrome/webdriver.py?line=72'>73</a>\u001b[0m                                 service_log_path, service, keep_alive)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:93\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=91'>92</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=92'>93</a>\u001b[0m     RemoteWebDriver\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=93'>94</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=94'>95</a>\u001b[0m         command_executor\u001b[39m=\u001b[39;49mChromiumRemoteConnection(\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=95'>96</a>\u001b[0m             remote_server_addr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mservice_url,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=96'>97</a>\u001b[0m             browser_name\u001b[39m=\u001b[39;49mbrowser_name, vendor_prefix\u001b[39m=\u001b[39;49mvendor_prefix,\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=97'>98</a>\u001b[0m             keep_alive\u001b[39m=\u001b[39;49mkeep_alive, ignore_proxy\u001b[39m=\u001b[39;49m_ignore_proxy),\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=98'>99</a>\u001b[0m         options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=99'>100</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/chromium/webdriver.py?line=100'>101</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquit()\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:269\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=266'>267</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_detector \u001b[39m=\u001b[39m file_detector \u001b[39mor\u001b[39;00m LocalFileDetector()\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=267'>268</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_client()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=268'>269</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_session(capabilities, browser_profile)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:360\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=356'>357</a>\u001b[0m w3c_caps \u001b[39m=\u001b[39m _make_w3c_caps(capabilities)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=357'>358</a>\u001b[0m parameters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcapabilities\u001b[39m\u001b[39m\"\u001b[39m: w3c_caps,\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=358'>359</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mdesiredCapabilities\u001b[39m\u001b[39m\"\u001b[39m: capabilities}\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=359'>360</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mNEW_SESSION, parameters)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=360'>361</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m response:\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=361'>362</a>\u001b[0m     response \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:425\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=422'>423</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=424'>425</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=425'>426</a>\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=426'>427</a>\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=427'>428</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=244'>245</a>\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=245'>246</a>\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=246'>247</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 99\nCurrent browser version is 101.0.4951.54 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00CC9943+2595139]\n\tOrdinal0 [0x00C5C9F1+2148849]\n\tOrdinal0 [0x00B54528+1066280]\n\tOrdinal0 [0x00B742C3+1196739]\n\tOrdinal0 [0x00B6FE37+1179191]\n\tOrdinal0 [0x00B6D6F1+1169137]\n\tOrdinal0 [0x00BA0530+1377584]\n\tOrdinal0 [0x00BA018A+1376650]\n\tOrdinal0 [0x00B9B806+1357830]\n\tOrdinal0 [0x00B76086+1204358]\n\tOrdinal0 [0x00B76F96+1208214]\n\tGetHandleVerifier [0x00E6B232+1658114]\n\tGetHandleVerifier [0x00F2312C+2411516]\n\tGetHandleVerifier [0x00D5F261+560433]\n\tGetHandleVerifier [0x00D5E366+556598]\n\tOrdinal0 [0x00C6286B+2173035]\n\tOrdinal0 [0x00C675F8+2192888]\n\tOrdinal0 [0x00C676E5+2193125]\n\tOrdinal0 [0x00C711FC+2232828]\n\tBaseThreadInitThunk [0x75C2FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A4E+238]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import uuid # used to create a unique 'computer' id for each recipe\n",
    "import json # used to store the scraped details\n",
    "import os\n",
    "\n",
    "from uuid import UUID # used to create a unique id for each recipe\n",
    "from json import JSONEncoder # used to convert the UUID into a writable format\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class data:\n",
    "    articles = []\n",
    "    count = 0\n",
    "    currentURL = \"\"\n",
    "    image_links = []\n",
    "    pages = []\n",
    "    recipe_details = {}\n",
    "    recipeLinks = []\n",
    "\n",
    "class scraper:\n",
    "    def intitialize(self, url, search_term, delay):\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "        \n",
    "        self.getURL(url) # Have to start somewhere\n",
    "        self.run(self)\n",
    "        self.closeSession() # Have to end somewhere\n",
    "\n",
    "    def run(self):\n",
    "        self.acceptCookies()\n",
    "        data.currentURL = self.findRecipeList(self)\n",
    "        self.getAllRecipePages(self, data.currentURL)\n",
    "        self.getRecipes(self, data.currentURL)\n",
    "        for i in data.recipeLinks:\n",
    "            data.currentURL = i\n",
    "            self.makeImage(self, data.currentURL)\n",
    "        self.closeSession()   \n",
    "\n",
    "    def getURL(url):\n",
    "        '''Navigates to a website using a url passed as a perameter.'''\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle():\n",
    "        '''Fetches the title and prints it to screen.'''\n",
    "        print(driver.title)\n",
    "\n",
    "    def closeSession():\n",
    "        '''Closes the driver after 3 seconds.'''\n",
    "        time.sleep(3)\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode():\n",
    "        '''Fetches source code for the page.'''\n",
    "        print(driver.page_source)\n",
    "\n",
    "    def search(search_term):\n",
    "        '''Finds search bar, types in the search term which it takes as a perameter and clicks to navigate to the next page.'''\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "            button.click()\n",
    "            try:\n",
    "                search_bar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "                try:\n",
    "                    search_bar.send_keys(search_term)\n",
    "                    search_bar.send_keys(Keys.RETURN) # Return = Enter\n",
    "                except:\n",
    "                    print(\"Exception: No search term input\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: No search bar found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Search bar\")\n",
    "\n",
    "    def home():\n",
    "        '''Finds the title and clicks it.'''\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "            title.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Title Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Title\")\n",
    "\n",
    "    def findRecipeList(self):\n",
    "        '''Finds the recipe tab and clicks it.'''\n",
    "        try:\n",
    "            button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "            button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Recipe List Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Recipe List\")\n",
    "\n",
    "        return self.getPageURL()\n",
    "\n",
    "    def acceptCookies():\n",
    "        '''Finds the accept cookies button and clicks it.'''\n",
    "        try:\n",
    "            cookie_button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "            cookie_button.click()\n",
    "            print(\"Removed Cookies\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exeption: Didnt Find Cookie Button\")\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout: Accept Cookie\")\n",
    "    \n",
    "    def getRecipes(self, url):\n",
    "        '''Finds the recipe container and puts all the recipes in a list.'''\n",
    "\n",
    "        try:\n",
    "            main = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='index-item-container']/div/div[2]/ul\"))) \n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Can't Find Recipe List\")\n",
    "        except TimeoutException: \n",
    "            print(\"Exception: Timeout: Can't Find Recipe List\")\n",
    "\n",
    "        data.articles = main.find_elements(By.TAG_NAME, 'li')\n",
    "        for i in data.articles:\n",
    "            tag = i.find_element(By.TAG_NAME, 'a')\n",
    "            data.recipeLinks.append(tag.get_attribute('href'))\n",
    "\n",
    "    def getPageURL():\n",
    "        '''Returns the current page url.'''\n",
    "        return driver.current_url\n",
    "\n",
    "    def getAllRecipePages(self, url):\n",
    "        '''Navigates to each recipe page by modifying the current url and stores them in a list.'''\n",
    "\n",
    "        try:\n",
    "            #total_pages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "            total_pages = [1, 2, 3, 4, 5] #temp to shorten runtime\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Total Pages Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Couldn't Find Total Pages\")\n",
    "\n",
    "        for i in total_pages:\n",
    "            data.currentURL = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = data.currentURL + url_change\n",
    "            data.pages.append(next_page)\n",
    "\n",
    "    def getUniqueID(self, url):\n",
    "        '''Creates a uuid for each recipe taking a url as a perameter'''\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "        #return ids\n",
    "\n",
    "    def getRecipeDetails(self, url):\n",
    "        self.getURL(url)\n",
    "\n",
    "        try:\n",
    "            try:    \n",
    "                name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Name Not Found\")\n",
    "                name = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Name\")\n",
    "                name = \"N/A\"  \n",
    "\n",
    "            try:\n",
    "                tag = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Tag Not Found\")\n",
    "                tag = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Tag\")\n",
    "                tag = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                description = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Description Not Found\")\n",
    "                description = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Description\")\n",
    "                description = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                time_total = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Total-Time Not Found\")\n",
    "                time_total = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Total-Time\")\n",
    "                time_total = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                time_prep = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Prep-Time Not Found\")\n",
    "                time_pre = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Prep-Time\")\n",
    "                time_pre = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                time_cook = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Cook-Time Not Found\")\n",
    "                time_cook = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Cook-Time\")\n",
    "                time_cook = \"N/A\" \n",
    "\n",
    "            try:\n",
    "                allergens = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Allergens Not Found\")\n",
    "                allergens = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Allergens\")\n",
    "                allergens = \"N/A\" \n",
    "\n",
    "            try: \n",
    "                swap = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Swap Not Found\")\n",
    "                swap = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Swap\")\n",
    "                swap = \"N/A\" \n",
    "            \n",
    "            try:\n",
    "                free_from = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Free-From Not Found\")\n",
    "                free_from = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Free-From\")\n",
    "                free_from = \"N/A\" \n",
    "\n",
    "            try:\n",
    "                ingredients = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Ingredients Not Found\")\n",
    "                ingredients = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Ingredients\")\n",
    "                ingredients = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                directions = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Directions Not Found\")\n",
    "                directions = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Directions\")\n",
    "                directions = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                notes = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Notes Not Found\")\n",
    "                notes = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Notes\")\n",
    "                notes = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                storage = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Storage Not Found\")\n",
    "                storage = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Storage\")\n",
    "                storage = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                picture_main = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Main Image Not Found\")\n",
    "                picture_main = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Main Image\")\n",
    "                picture_main = \"N/A\"\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: One Or More Data Entry Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find All Data Entries\")\n",
    "\n",
    "        image_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        image_list = image_container.find_elements(By.XPATH, 'img') # Find the children\n",
    "\n",
    "        for i in image_list:\n",
    "            link = i.get_attribute('src')\n",
    "            data.image_links.append(link)\n",
    "        \n",
    "        data.recipe_details = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        data.recipe_details['ID'].append(self.getUniqueID(self, url))\n",
    "        data.recipe_details['Name'].append(name)\n",
    "        data.recipe_details['Photo'].append(picture_main)\n",
    "        data.recipe_details['Tags'].append(tag)\n",
    "        data.recipe_details['Description'].append(description)\n",
    "        data.recipe_details['Total Time'].append(time_total)\n",
    "        data.recipe_details['Prep Time'].append(time_prep)\n",
    "        data.recipe_details['Cook Time'].append(time_cook)\n",
    "        data.recipe_details['Allergens'].append(allergens)\n",
    "        data.recipe_details['Swaps'].append(swap)\n",
    "        data.recipe_details['Free From'].append(free_from)\n",
    "        data.recipe_details['Ingredients'].append(ingredients)\n",
    "        data.recipe_details['Directions'].append(directions)\n",
    "        data.recipe_details['Notes'].append(notes)\n",
    "        data.recipe_details['Storage'].append(storage)\n",
    "        data.recipe_details['Images'].append(data.image_links)\n",
    "\n",
    "        self.jsonFile(self)\n",
    "\n",
    "    def jsonFile(self):\n",
    "        '''Creates a folder called 'raw_data' in the path for the json file to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folder already exists'''\n",
    "        try:\n",
    "            directory = \"raw_data\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Root Folder 'raw_data' Already Exists\")\n",
    "\n",
    "        '''Deals with TypeError: Object of type UUID is not JSON serializable by encoding the UUID'''\n",
    "        JSONEncoder_olddefault = JSONEncoder.default\n",
    "        def JSONEncoder_newdefault(self, o):\n",
    "            if isinstance(o, UUID): return str(o)\n",
    "            return JSONEncoder_olddefault(self, o)\n",
    "        JSONEncoder.default = JSONEncoder_newdefault\n",
    "\n",
    "        '''Stores data by writing the 'recipe_details' dictionary to a JSON file called 'data.json' in the folder just created\n",
    "        The dicrionary is converted to a string using str() to deal with 'TypeError: Object of type WebElement is not JSON serializable'''\n",
    "        with open(os.path.join('raw_data', 'data.json'), 'w') as json_file:\n",
    "            json.dump(str(data.recipe_details), json_file)\n",
    "\n",
    "    def downloadImage(url, recipeName):\n",
    "        '''Creates a folder called 'images' and another with the recipe name in the path for the image files to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folders already exists\n",
    "        Adds User-Agent Headers to bypass 403 error\n",
    "        Downloads the images into the folder of that recipe name'''\n",
    "        try:\n",
    "            directory = \"images\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Root Folder 'images' Already Exists\")\n",
    "\n",
    "        try:\n",
    "            recipeDirectory = recipeName.replace(\".jpg\", \"\").replace(\"0\", \"\").replace(\"1\", \"\").replace(\"2\", \"\").replace(\"3\", \"\").replace(\"4\", \"\").replace(\"5\", \"\").replace(\"6\", \"\").replace(\"7\", \"\").replace(\"8\", \"\").replace(\"9\", \"\")\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images\"\n",
    "            path = os.path.join(parent_dir, recipeDirectory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % recipeDirectory)\n",
    "        except:\n",
    "            print(\"Root Folder\", recipeDirectory,  \"Already Exists\")\n",
    "        \n",
    "        try:\n",
    "            # Adds headers to resolve 403 Fobidden Error\n",
    "            opener=urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            downloadDirectory = \"images/\" + recipeDirectory + \"/\"\n",
    "            fileType = '.jpg'\n",
    "            fileName = downloadDirectory + recipeName + fileType\n",
    "            image = urllib.request.urlretrieve(url, fileName)\n",
    "        except:\n",
    "            print(\"Error Downloading Images\")           \n",
    "\n",
    "    def makeImage(self, url):\n",
    "        '''Retrieves the ID of each image using 'getRecipeDetails()\n",
    "        Removes all unecissary elements from the ID string to create a file name\n",
    "        Pass the file name to 'downloadImages() to create a file'''\n",
    "        self.getRecipeDetails(self, url)\n",
    "        for i in data.recipe_details['Images']:\n",
    "            for j in i:\n",
    "                IDtoName = str(data.recipe_details['ID']).split()\n",
    "                IDtoName1 = str(IDtoName[0]).replace(\"(\", \"\")\n",
    "                IDtoName2 = str(IDtoName1).replace(\"[\", \"\")\n",
    "                IDtoName3 = str(IDtoName2).replace(\",\", \"\")\n",
    "                IDtoName4 = str(IDtoName3).replace(\"'\", \"\")\n",
    "\n",
    "                recipeName = IDtoName4 + \"-\" + str(data.count) + \".jpg\"\n",
    "                self.downloadImage(j, recipeName)\n",
    "                data.count = data.count + 1                \n",
    "        \n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons', 5)\n",
    "#scraper.testFunction(scraper)\n",
    "\n",
    "# IDEALS\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# make a separate main image\n",
    "# counts how many recipes there are on the site\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# bypass login\n",
    "# replace all XPaths with written XPaths\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument\n",
    "# seperate website specific methods from general functioning in a class\n",
    "# make sure all code works with any website so is reusable and genralisable\n",
    "# use the unique id (page url) to stop scraping recipes it has already scraped \n",
    "# have a wait for element function that takes a xpath and a perameter\n",
    "# time each function to optimise run speed\n",
    "# error handeling function? all error hadling is done by one function?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
