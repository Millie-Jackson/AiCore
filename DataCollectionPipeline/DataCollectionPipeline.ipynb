{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapeCookTime Exception: Timeout\n",
      "scrapeFreeFrom Exception: Timeout\n",
      "scrapeStorage Exception: Timeout\n",
      "ID APPEND: [('layered-chocolate-raspberry-mousse-999', UUID('0bd182de-ba77-4b5a-ac52-b31a8be20f81'))]\n",
      "makeRaw_DataFolder Error\n",
      "raw_data Folder Already Exists\n",
      "scrapeCookTime Exception: Timeout\n",
      "scrapeFreeFrom Exception: Timeout\n",
      "scrapeStorage Exception: Timeout\n",
      "ID APPEND: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "makeRaw_DataFolder Error\n",
      "raw_data Folder Already Exists\n",
      "make images 1: [['https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg']]\n",
      "i: ['https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg', 'https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg', 'https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg', 'https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg', 'https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg', 'https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg', 'https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg', 'https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg']\n",
      "j: https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/29/28/292887bd192056715b551f32f21ec84f.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/fb/83/fb831aec96ae91b7e6c669776a00bbcb.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/c9/42/c942203b104b9e236f7b62b68a421ab2.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/d4/73/d473f83d8da1536c02d08077bb847a45.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/06/d5/06d54c040db9681c86d905fc8941ec32.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/a5/7a/a57ae20ed7a6e8f6a88ed99a624754b1.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "j: https://cdn.pickuplimes.com/cache/56/ea/56eabc1063f218b99028f4f7479e68c9.jpg\n",
      "make images 2: [('layered-chocolate-raspberry-mousse-999', UUID('8600910c-daec-42d4-b906-ddb8a66ebad5'))]\n",
      "IDtoNamelayered-chocolate-raspberry-mousse-999\n",
      "Layered Chocolate Raspberry Mousse \n",
      "FINAL: Layered Chocolate Raspberry Mousse 0.jpg\n",
      "makeImagesFolder Error\n",
      "Images Folder Already Exists\n",
      "Directory 'Layered Chocolate Raspberry Mousse ' created\n",
      "Error Downloading Images\n",
      "scrapeAlternatives Exception: Timeout\n",
      "scrapeFreeFrom Exception: Timeout\n",
      "ID APPEND: [('caramel-shards-1001', UUID('812e01e8-0b1d-4d67-8889-8f29382f8245'))]\n",
      "makeRaw_DataFolder Error\n",
      "raw_data Folder Already Exists\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=102.0.5005.115)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003CB8F3+2406643]\n\tOrdinal0 [0x0035AF31+1945393]\n\tOrdinal0 [0x0024C610+837136]\n\tOrdinal0 [0x00240442+787522]\n\tOrdinal0 [0x00240C78+789624]\n\tOrdinal0 [0x002424B2+795826]\n\tOrdinal0 [0x0023BF09+769801]\n\tOrdinal0 [0x0024DAC0+842432]\n\tOrdinal0 [0x002A3E62+1195618]\n\tOrdinal0 [0x00294096+1130646]\n\tOrdinal0 [0x0026E636+976438]\n\tOrdinal0 [0x0026F546+980294]\n\tGetHandleVerifier [0x00639612+2498066]\n\tGetHandleVerifier [0x0062C920+2445600]\n\tGetHandleVerifier [0x00464F2A+579370]\n\tGetHandleVerifier [0x00463D36+574774]\n\tOrdinal0 [0x00361C0B+1973259]\n\tOrdinal0 [0x00366688+1992328]\n\tOrdinal0 [0x00366775+1992565]\n\tOrdinal0 [0x0036F8D1+2029777]\n\tBaseThreadInitThunk [0x7571FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77807A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77807A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 507>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=503'>504</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownloadImage(\u001b[39mself\u001b[39m, j, data\u001b[39m.\u001b[39mrecipeName)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=504'>505</a>\u001b[0m         data\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m                \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=506'>507</a>\u001b[0m scraper\u001b[39m.\u001b[39;49mintitialize(scraper, \u001b[39m'\u001b[39;49m\u001b[39mhttps://www.pickuplimes.com\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlemons\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.intitialize\u001b[1;34m(self, url, searchTerm, delay)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=71'>72</a>\u001b[0m global_ids \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39mgetUniqueID(scraper, \u001b[39m'\u001b[39m\u001b[39mhttps://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=73'>74</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetURL(url) \u001b[39m# Have to start somewhere\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=75'>76</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloseSession()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=169'>170</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetAllRecipePages(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=170'>171</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetRecipes(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=171'>172</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcycleRecipeLinks(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=172'>173</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloseSession()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.cycleRecipeLinks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=175'>176</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mrecipeLinks:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=176'>177</a>\u001b[0m     data\u001b[39m.\u001b[39mcurrentURL \u001b[39m=\u001b[39m i\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmakeImage(\u001b[39mself\u001b[39;49m, data\u001b[39m.\u001b[39;49mcurrentURL)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.makeImage\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=477'>478</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmakeImage\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=478'>479</a>\u001b[0m     \u001b[39m'''Retrieves the ID of each image using 'getRecipeDetails()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=479'>480</a>\u001b[0m \u001b[39m    Removes all unecissary elements from the ID string to create a file name\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=480'>481</a>\u001b[0m \u001b[39m    Pass the file name to 'downloadImages() to create a file'''\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=482'>483</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetRecipeDetails(\u001b[39mself\u001b[39;49m, url)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=483'>484</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmake images 1: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data\u001b[39m.\u001b[39mrecipeDetails[\u001b[39m'\u001b[39m\u001b[39mImages\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=485'>486</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mrecipeDetails[\u001b[39m'\u001b[39m\u001b[39mImages\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.exceptionHandling.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=86'>87</a>\u001b[0m \u001b[39mexcept\u001b[39;00m TimeoutException:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=87'>88</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Exception: Timeout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=88'>89</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.getRecipeDetails\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=373'>374</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeCookTime()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=374'>375</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeAllergens()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=375'>376</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscrapeAlternatives()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=376'>377</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeFreeFrom()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=377'>378</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscrapeIngredients()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.scrapeHandling.<locals>.wrapperOuter.<locals>.wrapperInner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=129'>130</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func) \u001b[39m# maintains introspection\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=130'>131</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapperInner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=131'>132</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=132'>133</a>\u001b[0m         func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=133'>134</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m NoSuchElementException:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=134'>135</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Exception:\u001b[39m\u001b[39m\"\u001b[39m, element, \u001b[39m\"\u001b[39m\u001b[39mNot Found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1'\u001b[0m in \u001b[0;36mscraper.scrapeAlternatives\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=319'>320</a>\u001b[0m \u001b[39m@scrapeHandling\u001b[39m(data\u001b[39m.\u001b[39malternatives)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=320'>321</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrapeAlternatives\u001b[39m():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=322'>323</a>\u001b[0m     data\u001b[39m.\u001b[39malternatives \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallergen-info-container\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/div[2]/div\u001b[39;49m\u001b[39m'\u001b[39;49m)))\u001b[39m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:78\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/wait.py?line=75'>76</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/wait.py?line=76'>77</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/wait.py?line=77'>78</a>\u001b[0m         value \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_driver)\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/wait.py?line=78'>79</a>\u001b[0m         \u001b[39mif\u001b[39;00m value:\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/wait.py?line=79'>80</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\support\\expected_conditions.py:64\u001b[0m, in \u001b[0;36mpresence_of_element_located.<locals>._predicate\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/expected_conditions.py?line=62'>63</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predicate\u001b[39m(driver):\n\u001b[1;32m---> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/support/expected_conditions.py?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m driver\u001b[39m.\u001b[39;49mfind_element(\u001b[39m*\u001b[39;49mlocator)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:1248\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=1244'>1245</a>\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=1245'>1246</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m-> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=1247'>1248</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=1248'>1249</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m'\u001b[39;49m: by,\n\u001b[0;32m   <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=1249'>1250</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m: value})[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:425\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=422'>423</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=424'>425</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=425'>426</a>\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=426'>427</a>\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=427'>428</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=244'>245</a>\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=245'>246</a>\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Millie/miniconda3/envs/DataCollectionPipeline/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=246'>247</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=102.0.5005.115)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x003CB8F3+2406643]\n\tOrdinal0 [0x0035AF31+1945393]\n\tOrdinal0 [0x0024C610+837136]\n\tOrdinal0 [0x00240442+787522]\n\tOrdinal0 [0x00240C78+789624]\n\tOrdinal0 [0x002424B2+795826]\n\tOrdinal0 [0x0023BF09+769801]\n\tOrdinal0 [0x0024DAC0+842432]\n\tOrdinal0 [0x002A3E62+1195618]\n\tOrdinal0 [0x00294096+1130646]\n\tOrdinal0 [0x0026E636+976438]\n\tOrdinal0 [0x0026F546+980294]\n\tGetHandleVerifier [0x00639612+2498066]\n\tGetHandleVerifier [0x0062C920+2445600]\n\tGetHandleVerifier [0x00464F2A+579370]\n\tGetHandleVerifier [0x00463D36+574774]\n\tOrdinal0 [0x00361C0B+1973259]\n\tOrdinal0 [0x00366688+1992328]\n\tOrdinal0 [0x00366775+1992565]\n\tOrdinal0 [0x0036F8D1+2029777]\n\tBaseThreadInitThunk [0x7571FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77807A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77807A6E+238]\n"
     ]
    }
   ],
   "source": [
    "import functools # used to maintain introspection on decorators\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import uuid # used to create a unique 'computer' id for each recipe\n",
    "import json # used to store the scraped details\n",
    "import os\n",
    "\n",
    "from uuid import UUID # used to create a unique id for each recipe\n",
    "from json import JSONEncoder # used to convert the UUID into a writable format\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "#from decorators import noSuchElementException\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class data:\n",
    "\n",
    "    articles = [] # Used to make a list of recipes\n",
    "    button = None # Used to interact with various button elements\n",
    "    container = None # Used to store various container elements\n",
    "    currentURL = \"\" # Used to store various urls \n",
    "    pages = [] # Used to append a list with pages links\n",
    "    recipeLinks = [] # Used to store recipe links\n",
    "    recipeName = \"\" # Stores the recipe name\n",
    "    searchbar = None # Used to interact with search bar\n",
    "    source = \"\" # Used to get page source code\n",
    "    tag = None # Used to store various tag elements\n",
    "    title = \"\" # Used to get the title\n",
    "    totalPages = [] # Stores a list of pages\n",
    "\n",
    "    # File Management\n",
    "    count = 0 # Used in the creation of image filenames\n",
    "    dataDirectory = \"\" # Used to create folder\n",
    "    imageDirectory = \"\" # Used to create folder \n",
    "    recipeDirectory = \"\" # Used to create modified folder names\n",
    "\n",
    "    # Scraped Information\n",
    "    recipeDetails = {} # Used to store all the scraped recipe details\n",
    "\n",
    "    allergens = \"\" # Used to store scraped allergens\n",
    "    alternatives = \"\" #Used to store scraped alternatives\n",
    "    description = \"\" # Used to store the scraped description of the recipe\n",
    "    freeFrom = \"\" # Used to store the scraped free from information\n",
    "    imageLinks = [] # Used to scrape all of a recipes image links\n",
    "    ingredients = \"\" # Used to store the scraped ingredients\n",
    "    instructions = \"\" # Used to store scraped instructions\n",
    "    mainPhoto = None # Used to store main photo link\n",
    "    name = \"\" # Used to store scraped recipe name\n",
    "    notes = \"\" # Used to store scraped recipe notes\n",
    "    recipeTags = \"\" # Used to store scraped recipe tags\n",
    "    storage = \"\" # Used to store scraped storage instructions\n",
    "    timeCook = \"\" # Used to store scraped cook time\n",
    "    timePrep = \"\" # Used to store scraped recipe  prep time \n",
    "    timeTotal = \"\" # Used to store scraped total time it takes to make the recipe\n",
    "\n",
    "class scraper:\n",
    "    def intitialize(self, url, searchTerm, delay):\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "    \n",
    "        self.getURL(url) # Have to start somewhere\n",
    "        self.run(self)\n",
    "        self.closeSession() # Have to end somewhere\n",
    "    \n",
    "    # DECORATORS\n",
    "\n",
    "    def exceptionHandling(func):\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                func(*args, **kwargs)\n",
    "            except NoSuchElementException:\n",
    "                print(f\"{func.__name__} Exception: Element Not Found\")\n",
    "            except TimeoutException:\n",
    "                print(f\"{func.__name__} Exception: Timeout\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def functionTimer(func):\n",
    "        \"\"\"Prints the functions runtime\"\"\"\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.perf_counter()\n",
    "            func(*args, **kwargs)\n",
    "            end = time.perf_counter()\n",
    "            runtime = end - start\n",
    "\n",
    "            print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    # Best applied to small convenience functions that you don’t call directly yourself\n",
    "    def debug(func):\n",
    "        \"\"\"Print the function signature and return value\"\"\"\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            args_repr = [repr(a) for a in args]                     # Creates a list of positional arguments, repr() returns a string for each argument               \n",
    "            kwargs_repr = [f\"{k}={v!r}\" for k, v in kwargs.items()] # Creates a list of keyword arguments, f-string formats each argument as key=value, !r specifier means that repr() is used to represent the value\n",
    "            signature = \", \".join(args_repr + kwargs_repr)          # Join both lists together to make a signature\n",
    "            print(f\"Calling {func.__name__}({signature})\")\n",
    "            func(*args, **kwargs)\n",
    "            print(f\"{func.__name__!r} returned {func!r}\")           \n",
    "            return func\n",
    "        return wrapper\n",
    "\n",
    "    # Best applied to functions you only need to call less often\n",
    "    def slowDown(func):\n",
    "        '''Sleep before calling the function'''\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            time.sleep(1)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def scrapeHandling(element):\n",
    "        def wrapperOuter(func):\n",
    "            @functools.wraps(func) # maintains introspection\n",
    "            def wrapperInner(*args, **kwargs):\n",
    "                try:\n",
    "                    func(*args, **kwargs)\n",
    "                except NoSuchElementException:\n",
    "                    print(f\"{func.__name__} Exception:\", element, \"Not Found\")\n",
    "                    element = \"N/A\"\n",
    "                except TimeoutException:\n",
    "                    print(f\"{func.__name__} Exception: Timeout\")\n",
    "                    element = \"N/A\"\n",
    "                return func\n",
    "            return wrapperInner\n",
    "        return wrapperOuter\n",
    "\n",
    "    def folderAlreadyExists(folderName):\n",
    "        def wrapperOuter(func):\n",
    "            @functools.wraps(func) # maintains introspection\n",
    "            def wrapperInner(*args, **kwargs):\n",
    "                try:\n",
    "                    func(*args, **kwargs)\n",
    "                except:\n",
    "                    print(f\"{func.__name__} Error\")\n",
    "                    print(folderName, \"Folder Already Exists\")\n",
    "                return func\n",
    "            return wrapperInner\n",
    "        return wrapperOuter\n",
    "    \n",
    "    # Counts the number of time the function has been called\n",
    "    def callCount(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            wrapper.calls += 1\n",
    "            print(f\"Call {wrapper.calls} of {func.__name__!r}\")\n",
    "            return func(*args, **kwargs)\n",
    "        wrapper.calls = 0\n",
    "        return wrapper\n",
    "\n",
    "    def run(self):\n",
    "        #self.acceptCookies()\n",
    "        data.currentURL = self.findRecipeList(self)\n",
    "        self.getAllRecipePages(self, data.currentURL)\n",
    "        self.getRecipes(self, data.currentURL)\n",
    "        self.cycleRecipeLinks(self)\n",
    "        self.closeSession()   \n",
    "\n",
    "    def cycleRecipeLinks(self):\n",
    "        for i in data.recipeLinks:\n",
    "            data.currentURL = i\n",
    "            self.makeImage(self, data.currentURL)\n",
    "\n",
    "    #@callCount\n",
    "    def getURL(url):\n",
    "        '''Navigates to a website using a url passed as a perameter.'''\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle():\n",
    "        '''Fetches the title and prints it to screen.'''\n",
    "        data.title = driver.title\n",
    "\n",
    "    def closeSession():\n",
    "        '''Closes the driver'''\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode():\n",
    "        '''Fetches source code for the page.'''\n",
    "        data.source = driver.page_source\n",
    "\n",
    "    @exceptionHandling\n",
    "    def search(self, searchTerm):\n",
    "        '''Finds search bar, types in the search term which it takes as a perameter and clicks to navigate to the next page.'''\n",
    "        button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "        button.click()\n",
    "\n",
    "        self.findSearchbar(self, searchTerm)\n",
    "\n",
    "    def searchbarTextAndClick(searchTerm):\n",
    "        try:\n",
    "            data.searchbar.send_keys(searchTerm)\n",
    "            data.searchbar.send_keys(Keys.RETURN) # Return = Enter\n",
    "        except:\n",
    "            print(\"Exception: No search term input\")\n",
    "    \n",
    "    @exceptionHandling\n",
    "    def findSearchbar(self, searchTerm):\n",
    "\n",
    "        data.searchbar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "        self.searchbarTextAndClick(searchTerm)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def home():\n",
    "        '''Finds the title and clicks it.'''\n",
    "        title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "        title.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def findRecipeList(self):\n",
    "        '''Finds the recipe tab and clicks it.'''\n",
    "        data.button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "        data.button.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def acceptCookies():\n",
    "        '''Finds the accept cookies button and clicks it.'''\n",
    "        data.button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "        data.button.click()\n",
    "    \n",
    "    def getRecipes(self, url):\n",
    "        '''Finds the recipe container and puts all the recipes in a list.'''\n",
    "\n",
    "        self.getRecipeContainer()\n",
    "        self.makeRecipeList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeContainer():\n",
    "        data.container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='index-item-container']/div/div[2]/ul\"))) \n",
    "\n",
    "    def makeRecipeList():\n",
    "        data.articles = data.container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for i in data.articles:\n",
    "            data.tag = i.find_element(By.TAG_NAME, 'a')\n",
    "            data.recipeLinks.append(data.tag.get_attribute('href'))\n",
    "\n",
    "    def getPageURL():\n",
    "        '''Returns the current page url.'''\n",
    "        data.currentURL =  driver.current_url\n",
    "\n",
    "    def getAllRecipePages(self, url):\n",
    "        '''Navigates to each recipe page by modifying the current url and stores them in a list.'''\n",
    "\n",
    "        self.getTotalPages()\n",
    "        self.getSearchList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getTotalPages():\n",
    "         #totalPages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "        data.totalPages = [1, 2, 3] #temp to shorten runtime\n",
    "\n",
    "    def getSearchList():\n",
    "        for i in data.totalPages:\n",
    "            data.currentURL = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = data.currentURL + url_change\n",
    "            data.pages.append(next_page)\n",
    "\n",
    "    def getUniqueID(self, url):\n",
    "        '''Creates a uuid for each recipe taking a url as a perameter'''\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "        return ids\n",
    "\n",
    "    @scrapeHandling(data.name)\n",
    "    def scrapeName():\n",
    "\n",
    "        data.name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "\n",
    "    @scrapeHandling(data.recipeTags)\n",
    "    def scrapeTags():\n",
    "\n",
    "        data.recipeTags = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "\n",
    "    @scrapeHandling(data.description)\n",
    "    def scrapeDescription():\n",
    "\n",
    "        data.description = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "\n",
    "    @scrapeHandling(data.timeTotal)\n",
    "    def scrapeTotalTime():\n",
    "        \n",
    "        data.timeTotal = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "\n",
    "    @scrapeHandling(data.timePrep)\n",
    "    def scrapePrepTime():\n",
    "\n",
    "        data.timePrep = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "\n",
    "    @scrapeHandling(data.timeCook)\n",
    "    def scrapeCookTime():\n",
    "        \n",
    "        data.timeCook = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "\n",
    "    @scrapeHandling(data.allergens)\n",
    "    def scrapeAllergens():\n",
    "\n",
    "        data.allergens = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "\n",
    "    @scrapeHandling(data.alternatives)\n",
    "    def scrapeAlternatives():\n",
    "        \n",
    "        data.alternatives = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "\n",
    "    @scrapeHandling(data.freeFrom)\n",
    "    def scrapeFreeFrom():\n",
    "        \n",
    "        data.freeFrom = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text \n",
    "\n",
    "    @scrapeHandling(data.ingredients)\n",
    "    def scrapeIngredients():\n",
    "        \n",
    "        data.ingredients = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "\n",
    "    @scrapeHandling(data.instructions)\n",
    "    def scrapeInstructions():\n",
    "        \n",
    "        data.instructions = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "\n",
    "    @scrapeHandling(data.notes)\n",
    "    def scrapeNotes():\n",
    "        \n",
    "        data.notes = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "\n",
    "    @scrapeHandling(data.storage)\n",
    "    def scrapeStorage():\n",
    "        \n",
    "        data.storage = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "\n",
    "    @scrapeHandling(data.mainPhoto)\n",
    "    def scrapeMainPhoto():\n",
    "        \n",
    "        data.mainPhoto = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "\n",
    "\n",
    "    @exceptionHandling\n",
    "    def scrapeImages():\n",
    "        imageContainer = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        imageList = imageContainer.find_elements(By.XPATH, 'img') # Find the children\n",
    "\n",
    "        for i in imageList:\n",
    "            link = i.get_attribute('src')\n",
    "            data.imageLinks.append(link)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeDetails(self, url):\n",
    "        self.getURL(url)\n",
    "\n",
    "        self.scrapeName()  \n",
    "        self.scrapeTags()\n",
    "        self.scrapeDescription()\n",
    "        self.scrapeTotalTime()\n",
    "        self.scrapePrepTime()\n",
    "        self.scrapeCookTime()\n",
    "        self.scrapeAllergens()\n",
    "        self.scrapeAlternatives()\n",
    "        self.scrapeFreeFrom()\n",
    "        self.scrapeIngredients()\n",
    "        self.scrapeInstructions()\n",
    "        self.scrapeNotes()\n",
    "        self.scrapeStorage()\n",
    "        self.scrapeMainPhoto()\n",
    "        self.scrapeImages()\n",
    "\n",
    "        self.storeDetails(self, url)\n",
    "        self.jsonFile(self)\n",
    "\n",
    "    def storeDetails(self, url):\n",
    "        data.recipeDetails = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        data.recipeDetails['ID'].append(self.getUniqueID(self, url))\n",
    "        data.recipeDetails['Name'].append(data.name)\n",
    "        data.recipeDetails['Photo'].append(data.mainPhoto)\n",
    "        data.recipeDetails['Tags'].append(data.recipeTags)\n",
    "        data.recipeDetails['Description'].append(data.description)\n",
    "        data.recipeDetails['Total Time'].append(data.timeTotal)\n",
    "        data.recipeDetails['Prep Time'].append(data.timePrep)\n",
    "        data.recipeDetails['Cook Time'].append(data.timeCook)\n",
    "        data.recipeDetails['Allergens'].append(data.allergens)\n",
    "        data.recipeDetails['Swaps'].append(data.alternatives)\n",
    "        data.recipeDetails['Free From'].append(data.freeFrom)\n",
    "        data.recipeDetails['Ingredients'].append(data.ingredients)\n",
    "        data.recipeDetails['Directions'].append(data.instructions)\n",
    "        data.recipeDetails['Notes'].append(data.notes)\n",
    "        data.recipeDetails['Storage'].append(data.storage)\n",
    "        data.recipeDetails['Images'].append(data.imageLinks)\n",
    "\n",
    "    def jsonFile(self):\n",
    "        '''Creates a folder called 'raw_data' in the path for the json file to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folder already exists'''\n",
    "\n",
    "        self.makeRaw_DataFolder()\n",
    "\n",
    "        '''Deals with TypeError: Object of type UUID is not JSON serializable by encoding the UUID'''\n",
    "        JSONEncoder_olddefault = JSONEncoder.default\n",
    "        def JSONEncoder_newdefault(self, o):\n",
    "            if isinstance(o, UUID): return str(o)\n",
    "            return JSONEncoder_olddefault(self, o)\n",
    "        JSONEncoder.default = JSONEncoder_newdefault\n",
    "\n",
    "        self.jsonDump()\n",
    "\n",
    "    @folderAlreadyExists(\"raw_data\")\n",
    "    def makeRaw_DataFolder():\n",
    "        \n",
    "        data.dataDirectory = \"raw_data\"\n",
    "        parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "        path = os.path.join(parent_dir, data.dataDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.dataDirectory)\n",
    "    \n",
    "    def jsonDump():\n",
    "        '''Stores data by writing the 'recipe_details' dictionary to a JSON file called 'data.json' in the folder just created\n",
    "        The dicrionary is converted to a string using str() to deal with 'TypeError: Object of type WebElement is not JSON serializable'''\n",
    "        with open(os.path.join('raw_data', 'data.json'), 'w') as json_file:\n",
    "            json.dump(str(data.recipeDetails), json_file)\n",
    "\n",
    "    def downloadImage(self, url, recipeName):\n",
    "        '''Creates a folder called 'images' and another with the recipe name in the path for the image files to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folders already exists\n",
    "        Adds User-Agent Headers to bypass 403 error\n",
    "        Downloads the images into the folder of that recipe name'''\n",
    "\n",
    "        self.makeImagesFolder()\n",
    "        self.makeRecipeFolder()\n",
    "        \n",
    "        try:\n",
    "            # Adds headers to resolve 403 Fobidden Error\n",
    "            opener=urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            downloadDirectory = \"images/\" + data.recipeDirectory + \"/\"\n",
    "            fileType = '.jpg'\n",
    "            fileName = downloadDirectory + recipeName + fileType\n",
    "            image = urllib.request.urlretrieve(url, fileName)\n",
    "        except:\n",
    "            print(\"Error Downloading Images\")           \n",
    "\n",
    "    @folderAlreadyExists(\"Images\")\n",
    "    def makeImagesFolder():\n",
    "        \n",
    "        data.imageDirectory = \"images\"\n",
    "        parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "        path = os.path.join(parent_dir, data.imageDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.imageDirectory)\n",
    "\n",
    "    @folderAlreadyExists(\"Recipe\")\n",
    "    def makeRecipeFolder():\n",
    "\n",
    "        data.recipeDirectory = data.recipeName.replace(\".jpg\", \"\").replace(\"0\", \"\").replace(\"1\", \"\").replace(\"2\", \"\").replace(\"3\", \"\").replace(\"4\", \"\").replace(\"5\", \"\").replace(\"6\", \"\").replace(\"7\", \"\").replace(\"8\", \"\").replace(\"9\", \"\")\n",
    "        parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images\"\n",
    "        path = os.path.join(parent_dir, data.recipeDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.recipeDirectory)\n",
    "\n",
    "    def makeImage(self, url):\n",
    "        '''Retrieves the ID of each image using 'getRecipeDetails()\n",
    "        Removes all unecissary elements from the ID string to create a file name\n",
    "        Pass the file name to 'downloadImages() to create a file'''\n",
    "        \n",
    "        self.getRecipeDetails(self, url)\n",
    "        \n",
    "        for i in data.recipeDetails['Images']:\n",
    "\n",
    "            for j in i:\n",
    "                IDtoName = data.recipeDetails['ID'][0]\n",
    "                IDtoName = IDtoName[0].replace(\"-\", \" \")\n",
    "                IDtoName = IDtoName.title()\n",
    "\n",
    "                for i in IDtoName:\n",
    "                    if i.isdigit():\n",
    "                        IDtoName = IDtoName.replace(i, \"\")\n",
    "\n",
    "        s = str(data.count)\n",
    "        data.recipeName = IDtoName + s + \".jpg\"\n",
    "        self.downloadImage(self, j, data.recipeName)\n",
    "        data.count = data.count + 1                \n",
    "\n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons', 5)\n",
    "\n",
    "# IDEALS ---------------------------------------------------------------------------------------------------------------\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# make a separate main image\n",
    "# counts how many recipes there are on the site\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# bypass login\n",
    "# replace all XPaths with written XPaths\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument\n",
    "# seperate website specific methods from general functioning in a class\n",
    "# make sure all code works with any website so is reusable and genralisable\n",
    "# use the unique id (page url) to stop scraping recipes it has already scraped \n",
    "# have a wait for element function that takes a xpath and a perameter\n",
    "# time each function to optimise run speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".............................................."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_getURL\n",
      "Website Found\n",
      "test_makeImage\n",
      "test_makeRecipeFolder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 46 tests in 0.163s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x288ae73ce80>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os # for testing directories\n",
    "import requests # for testing website response\n",
    "import unittest\n",
    "import uuid # for testing the recipe unique identifyer\n",
    "from scraper import scraper\n",
    "\n",
    "class scraperTestCase(unittest.TestCase):\n",
    "\n",
    "    recipe = 'harissa-spiced-beans-898-0.jpg'\n",
    "    directory = 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images'\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls): # Runs at the begining of the file\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls): # Runs at the end of the file\n",
    "        pass\n",
    "\n",
    "    def setUp(self): # Runs before every test\n",
    "        self.bot1 = scraper() \n",
    "        self.friendlyID = 'harissa-spiced-beans-898'\n",
    "        self.systemID = uuid.uuid4()\n",
    "        self.dictionary = {\"ID\": []}\n",
    "        self.number = str(3)\n",
    "        #self.handle = open(\"data.json\", \"r\") # Dont forget to test the json file\n",
    "\n",
    "    def tearDown(self): # Runs at the end of every test\n",
    "        del self.bot1\n",
    "    \n",
    "    def test_dataClass(self):\n",
    "        pass\n",
    "    \n",
    "    def test_decoratorClass(self):\n",
    "        pass\n",
    "\n",
    "    def test_exceptionHandling(self):\n",
    "        pass\n",
    "\n",
    "    def test_run(self):\n",
    "        pass\n",
    "\n",
    "    def test_cycleRecipeLinks(self):\n",
    "        pass\n",
    "\n",
    "    def test_getURL(self):\n",
    "        print(\"test_getURL\")\n",
    "        response = requests.get('https://www.pickuplimes.com/')\n",
    "\n",
    "        if response.ok:\n",
    "            print(\"Website Found\")\n",
    "            return response.text\n",
    "        else:\n",
    "            print(\"!Website Not Found!\")\n",
    "            return 'Bad Response'\n",
    "\n",
    "    def test_getTitle(self):\n",
    "        pass\n",
    "\n",
    "    def test_closeSession(self):\n",
    "        pass\n",
    "\n",
    "    def test_getSourceCode(self):\n",
    "        pass\n",
    "\n",
    "    def test_search(self):\n",
    "        pass\n",
    "\n",
    "    def test_searchbarTextAndClick(self):\n",
    "        pass\n",
    "\n",
    "    def test_findSearchbar(self):\n",
    "        pass\n",
    "\n",
    "    def test_home(self):\n",
    "        pass\n",
    "\n",
    "    def test_findRecipeList(self):\n",
    "        pass\n",
    "\n",
    "    def test_acceptCookies(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipes(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipeContainer(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeRecipeList(self):\n",
    "        pass\n",
    "\n",
    "    def test_getPageURL(self):\n",
    "        pass\n",
    "\n",
    "    def test_getAllRecipePages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getTotalPages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getSearchList(self):\n",
    "        pass\n",
    "\n",
    "    def test_getUniqueID(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeName(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeTags(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeDescription(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeTotalTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapePrepTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeCookTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeAllergens(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeAlternatives(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeFreeFrom(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeIngredients(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeInstructions(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeInstructions(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeNotes(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeStorage(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeMainPhoto(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeImages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipeDetails(self):\n",
    "        pass\n",
    "\n",
    "    def test_storeDetails(self):\n",
    "        pass\n",
    "\n",
    "    def test_jsonFile(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeRaw_DataFolder(self):\n",
    "        pass\n",
    "\n",
    "    def jsonDump(self):\n",
    "        pass\n",
    "\n",
    "    def test_downloadImage(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeImagesFolder(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeRecipeFolder(self):\n",
    "        print('test_makeRecipeFolder')\n",
    "\n",
    "        self.assertEqual(self.recipe.replace(\".jpg\", \"\").replace(\"0\", \"\"), 'harissa-spiced-beans-898-')\n",
    "        self.assertEqual(self.directory, 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images')\n",
    "        self.assertEqual(os.path.join(self.directory, self.recipe), 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/images\\harissa-spiced-beans-898-0.jpg')\n",
    "\n",
    "    def test_makeImage(self):\n",
    "        print(\"test_makeImage\")\n",
    "\n",
    "        self.dictionary['ID'].append(self.friendlyID)\n",
    "        self.dictionary['ID'].append(self.systemID)\n",
    "\n",
    "        # Check the dictionary contains the correct IDs\n",
    "        self.assertEqual(self.dictionary['ID'][0], self.friendlyID)\n",
    "        self.assertAlmostEqual(self.dictionary['ID'][1], self.systemID)\n",
    "\n",
    "        # Check it removes all unnecessary bits from the string\n",
    "        editedID = (self.dictionary['ID'][0])\n",
    "        editedID = editedID.title()\n",
    "        editedID = editedID.replace(\"-\", \" \")\n",
    "        for i in editedID:\n",
    "            if i.isdigit():\n",
    "                editedID = editedID.replace(i , \"\")\n",
    "\n",
    "        # Check the finished string is correct\n",
    "        name = editedID + self.number + \".jpg\"\n",
    "        self.assertEqual(name, editedID + self.number + \".jpg\")     \n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    test_scraper() \n",
    "#    print(\"Passed\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
