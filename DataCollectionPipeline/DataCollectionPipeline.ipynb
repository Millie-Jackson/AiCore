{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=103.0.5060.134)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00B36463+2188387]\n\tOrdinal0 [0x00ACE461+1762401]\n\tOrdinal0 [0x009E3C40+801856]\n\tOrdinal0 [0x009D8932+756018]\n\tOrdinal0 [0x009D9168+758120]\n\tOrdinal0 [0x009DAA22+764450]\n\tOrdinal0 [0x009D4379+738169]\n\tOrdinal0 [0x009E50D0+807120]\n\tOrdinal0 [0x00A3C402+1164290]\n\tOrdinal0 [0x00A2C5F6+1099254]\n\tOrdinal0 [0x00A06BE0+945120]\n\tOrdinal0 [0x00A07AD6+948950]\n\tGetHandleVerifier [0x00DD71F2+2712546]\n\tGetHandleVerifier [0x00DC886D+2652765]\n\tGetHandleVerifier [0x00BC002A+520730]\n\tGetHandleVerifier [0x00BBEE06+516086]\n\tOrdinal0 [0x00AD468B+1787531]\n\tOrdinal0 [0x00AD8E88+1805960]\n\tOrdinal0 [0x00AD8F75+1806197]\n\tOrdinal0 [0x00AE1DF1+1842673]\n\tBaseThreadInitThunk [0x7598FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76F57A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76F57A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 910>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=906'>907</a>\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=907'>908</a>\u001b[0m                     data\u001b[39m.\u001b[39mcount \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=909'>910</a>\u001b[0m scraper\u001b[39m.\u001b[39;49mintitialize(scraper, \u001b[39m'\u001b[39;49m\u001b[39mhttps://www.pickuplimes.com\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlemons\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1\u001b[0m in \u001b[0;36mscraper.intitialize\u001b[1;34m(self, url, searchTerm, delay)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=98'>99</a>\u001b[0m global_ids \u001b[39m=\u001b[39m scraper\u001b[39m.\u001b[39mgetUniqueID(scraper, \u001b[39m'\u001b[39m\u001b[39mhttps://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=100'>101</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetURL(\u001b[39mself\u001b[39m, url) \u001b[39m# Have to start somewhere\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=101'>102</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=102'>103</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcloseSession()\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1\u001b[0m in \u001b[0;36mscraper.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=196'>197</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=197'>198</a>\u001b[0m \u001b[39mThis function calls all the necissary functions in order.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=198'>199</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=205'>206</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=206'>207</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=208'>209</a>\u001b[0m \u001b[39m#self.acceptCookies()\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=209'>210</a>\u001b[0m data\u001b[39m.\u001b[39mcurrentURL \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfindRecipeList(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=210'>211</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetAllRecipePages(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=211'>212</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetRecipes(\u001b[39mself\u001b[39m, data\u001b[39m.\u001b[39mcurrentURL)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1\u001b[0m in \u001b[0;36mscraper.exceptionHandling.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=113'>114</a>\u001b[0m \u001b[39mexcept\u001b[39;00m TimeoutException:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=114'>115</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Exception: Timeout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=115'>116</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\Millie\\Documents\\AiCore\\AiCore\\DataCollectionPipeline\\DataCollectionPipeline.ipynb Cell 1\u001b[0m in \u001b[0;36mscraper.findRecipeList\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=341'>342</a>\u001b[0m \u001b[39m@exceptionHandling\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=342'>343</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindRecipeList\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=343'>344</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=344'>345</a>\u001b[0m \u001b[39m    Finds the recipe tab and clicks it.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=345'>346</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=349'>350</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=350'>351</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=352'>353</a>\u001b[0m     data\u001b[39m.\u001b[39mbutton \u001b[39m=\u001b[39m WebDriverWait(driver,\u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49mpresence_of_element_located((By\u001b[39m.\u001b[39;49mLINK_TEXT, \u001b[39m'\u001b[39;49m\u001b[39mRecipes\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/DataCollectionPipeline.ipynb#ch0000000?line=353'>354</a>\u001b[0m     data\u001b[39m.\u001b[39mbutton\u001b[39m.\u001b[39mclick()\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py:78\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         value \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_driver)\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m value:\n\u001b[0;32m     80\u001b[0m             \u001b[39mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\support\\expected_conditions.py:64\u001b[0m, in \u001b[0;36mpresence_of_element_located.<locals>._predicate\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predicate\u001b[39m(driver):\n\u001b[1;32m---> 64\u001b[0m     \u001b[39mreturn\u001b[39;00m driver\u001b[39m.\u001b[39;49mfind_element(\u001b[39m*\u001b[39;49mlocator)\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:1248\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m   1246\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m-> 1248\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\n\u001b[0;32m   1249\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m'\u001b[39;49m: by,\n\u001b[0;32m   1250\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m: value})[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:425\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    426\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    427\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    428\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Millie\\miniconda3\\envs\\DataCollectionPipeline\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=103.0.5060.134)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00B36463+2188387]\n\tOrdinal0 [0x00ACE461+1762401]\n\tOrdinal0 [0x009E3C40+801856]\n\tOrdinal0 [0x009D8932+756018]\n\tOrdinal0 [0x009D9168+758120]\n\tOrdinal0 [0x009DAA22+764450]\n\tOrdinal0 [0x009D4379+738169]\n\tOrdinal0 [0x009E50D0+807120]\n\tOrdinal0 [0x00A3C402+1164290]\n\tOrdinal0 [0x00A2C5F6+1099254]\n\tOrdinal0 [0x00A06BE0+945120]\n\tOrdinal0 [0x00A07AD6+948950]\n\tGetHandleVerifier [0x00DD71F2+2712546]\n\tGetHandleVerifier [0x00DC886D+2652765]\n\tGetHandleVerifier [0x00BC002A+520730]\n\tGetHandleVerifier [0x00BBEE06+516086]\n\tOrdinal0 [0x00AD468B+1787531]\n\tOrdinal0 [0x00AD8E88+1805960]\n\tOrdinal0 [0x00AD8F75+1806197]\n\tOrdinal0 [0x00AE1DF1+1842673]\n\tBaseThreadInitThunk [0x7598FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x76F57A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76F57A6E+238]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import functools # used to maintain introspection on decorators\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import uuid # used to create a unique 'computer' id for each recipe\n",
    "import json # used to store the scraped details\n",
    "import os\n",
    "\n",
    "from uuid import UUID # used to create a unique id for each recipe\n",
    "from json import JSONEncoder # used to convert the UUID into a writable format\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "#from decorators import noSuchElementException\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class data:\n",
    "    '''\n",
    "    This class contains all the attributes of the scraper\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "    '''\n",
    "\n",
    "    articles = [] # Used to make a list of recipes\n",
    "    button = None # Used to interact with various button elements\n",
    "    container = None # Used to store various container elements\n",
    "    currentURL = \"\" # Used to store various urls \n",
    "    pages = [] # Used to append a list with pages links\n",
    "    recipeLinks = [] # Used to store recipe links\n",
    "    searchbar = None # Used to interact with search bar\n",
    "    source = \"\" # Used to get page source code\n",
    "    tag = None # Used to store various tag elements\n",
    "    title = \"\" # Used to get the title\n",
    "    totalPages = [] # Stores a list of pages\n",
    "\n",
    "    # File Management\n",
    "    count = 0 # Used in the creation of image filenames\n",
    "    parentDirectory = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/\" # Project directory\n",
    "    dataDirectory = \"\" # Used to create folder\n",
    "    imageDirectory = \"\" # Used to create folder \n",
    "    recipeDirectory = \"\" # Used to create modified folder names\n",
    "    imageFileName = \"\" # Used to create image files\n",
    "\n",
    "    # Scraped Information\n",
    "    recipeDetails = {} # Used to store all the scraped recipe details\n",
    "    imageScrapeLimiter = 0 # Used to limit the amount of times an image is scraped\n",
    "\n",
    "    allergens = \"\" # Used to store scraped allergens\n",
    "    alternatives = \"\" #Used to store scraped alternatives\n",
    "    description = \"\" # Used to store the scraped description of the recipe\n",
    "    freeFrom = \"\" # Used to store the scraped free from information\n",
    "    imageLinks = [] # Used to scrape all of a recipes image links\n",
    "    ingredients = \"\" # Used to store the scraped ingredients\n",
    "    instructions = \"\" # Used to store scraped instructions\n",
    "    mainPhoto = None # Used to store main photo link\n",
    "    name = \"\" # Used to store scraped recipe name\n",
    "    notes = \"\" # Used to store scraped recipe notes\n",
    "    recipeTags = \"\" # Used to store scraped recipe tags\n",
    "    storage = \"\" # Used to store scraped storage instructions\n",
    "    timeCook = \"\" # Used to store scraped cook time\n",
    "    timePrep = \"\" # Used to store scraped recipe  prep time \n",
    "    timeTotal = \"\" # Used to store scraped total time it takes to make the recipe\n",
    "\n",
    "class scraper:\n",
    "    '''\n",
    "    This class is the main scraper. \n",
    "\n",
    "    This class will navigate through a webpage and scrape data into a json file and images into a folder separated into recipes.\n",
    "\n",
    "    Attributes:\n",
    "    '''\n",
    "\n",
    "    def intitialize(self, url, searchTerm, delay):\n",
    "        '''\n",
    "        This function intitializes the scraper class.\n",
    "\n",
    "        Arg:\n",
    "            url (str): The target website\n",
    "            searchTerm (str): The word we want to type into the search bar\n",
    "            delay (int): The number of seconds used to delay a wait for elemnt and timeout exeptions\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "    \n",
    "        self.getURL(self, url) # Have to start somewhere\n",
    "        self.run(self)\n",
    "        self.closeSession() # Have to end somewhere\n",
    "    \n",
    "    # DECORATORS\n",
    "\n",
    "    def exceptionHandling(func):\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                func(*args, **kwargs)\n",
    "            except NoSuchElementException:\n",
    "                print(f\"{func.__name__} Exception: Element Not Found\")\n",
    "            except TimeoutException:\n",
    "                print(f\"{func.__name__} Exception: Timeout\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def functionTimer(func):\n",
    "        \"\"\"Prints the functions runtime\"\"\"\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = time.perf_counter()\n",
    "            func(*args, **kwargs)\n",
    "            end = time.perf_counter()\n",
    "            runtime = end - start\n",
    "            print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    # Best applied to small convenience functions that you donâ€™t call directly yourself\n",
    "    def debug(func):\n",
    "        \"\"\"Print the function signature and return value\"\"\"\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            args_repr = [repr(a) for a in args]                     # Creates a list of positional arguments, repr() returns a string for each argument               \n",
    "            kwargs_repr = [f\"{k}={v!r}\" for k, v in kwargs.items()] # Creates a list of keyword arguments, f-string formats each argument as key=value, !r specifier means that repr() is used to represent the value\n",
    "            signature = \", \".join(args_repr + kwargs_repr)          # Join both lists together to make a signature\n",
    "            print(f\"Calling {func.__name__}({signature})\")\n",
    "            func(*args, **kwargs)\n",
    "            print(f\"{func.__name__!r} returned {func!r}\")           \n",
    "            return func\n",
    "        return wrapper\n",
    "\n",
    "    # Best applied to functions you only need to call less often\n",
    "    def slowDown(func):\n",
    "        '''Sleep before calling the function'''\n",
    "        @functools.wraps(func) # maintains introspection\n",
    "        def wrapper(*args, **kwargs):\n",
    "            time.sleep(1)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def scrapeHandling(element):\n",
    "        '''Wraps all scrape functions with exception handling'''\n",
    "        def wrapperOuter(func):\n",
    "            @functools.wraps(func) # maintains introspection\n",
    "            def wrapperInner(*args, **kwargs):\n",
    "                try:\n",
    "                    func(*args, **kwargs)\n",
    "                except NoSuchElementException:\n",
    "                    #print(f\"{func.__name__} Exception:\", element, \"Not Found\")\n",
    "                    element = \"N/A\"\n",
    "                except TimeoutException:\n",
    "                    #print(f\"{func.__name__} Exception: Timeout\")\n",
    "                    element = \"N/A\"\n",
    "                return func\n",
    "            return wrapperInner\n",
    "        return wrapperOuter\n",
    "\n",
    "    def folderAlreadyExists(folderName) -> None:\n",
    "        '''Handels the folder already exists exeption in the folder creation functions'''\n",
    "        def wrapperOuter(func):\n",
    "            @functools.wraps(func) # maintains introspection\n",
    "            def wrapperInner(*args, **kwargs):\n",
    "                try:\n",
    "                    func(*args, **kwargs)\n",
    "                except:\n",
    "                    #print(f\"{func.__name__} Error\")\n",
    "                    #print(folderName, \"Folder Already Exists\")\n",
    "                    pass\n",
    "                return func\n",
    "            return wrapperInner\n",
    "        return wrapperOuter\n",
    "    \n",
    "    def callCount(func) -> None:\n",
    "        '''Counts the number of time the function has been called.'''\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            wrapper.calls += 1\n",
    "            print(f\"Call {wrapper.calls} of {func.__name__!r}\")\n",
    "            return func(*args, **kwargs)\n",
    "        wrapper.calls = 0\n",
    "        return wrapper\n",
    "\n",
    "    def run(self) -> None:\n",
    "        '''\n",
    "        This function calls all the necissary functions in order.\n",
    "\n",
    "        The order of function calls is for the class to navigate \n",
    "        through the website and scrape the text and images.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        #self.acceptCookies()\n",
    "        data.currentURL = self.findRecipeList(self)\n",
    "        self.getAllRecipePages(self, data.currentURL)\n",
    "        self.getRecipes(self, data.currentURL)\n",
    "        self.cycleRecipeLinks(self)\n",
    "        self.closeSession()   \n",
    "\n",
    "    def cycleRecipeLinks(self) -> None:\n",
    "        '''\n",
    "        This function iterates though the list of recipe urls, passing each url to the makeImage() function.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        for i in data.recipeLinks:\n",
    "            data.currentURL = i\n",
    "            self.makeImage(self, data.currentURL)\n",
    "\n",
    "    def getURL(self, url) -> None:\n",
    "        '''\n",
    "        Navigates to a website using a url passed as a perameter.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The target website\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle() -> None:\n",
    "        '''\n",
    "        Fetches the title.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        data.title = driver.title\n",
    "\n",
    "    def closeSession() -> None:\n",
    "        '''\n",
    "        Closes the driver\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode() -> None:\n",
    "        '''\n",
    "        Fetches the current pages source code.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.source = driver.page_source\n",
    "\n",
    "    @exceptionHandling\n",
    "    def search(self, searchTerm) -> None:\n",
    "        '''\n",
    "        Finds search bar and clicks it ready for input.\n",
    "        \n",
    "        Args:\n",
    "            searchTerm (str): The word passed to the findSearchBar() fucntion that types into the search box\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Find searchbar and click\n",
    "        button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "        button.click()\n",
    "\n",
    "        self.findSearchbar(self, searchTerm)\n",
    "\n",
    "    def searchbarTextAndClick(searchTerm) -> None:\n",
    "        '''\n",
    "        This function types the searchTerm into the searchbar and presses enter which then navigates to the search results page.\n",
    "\n",
    "        Args:\n",
    "            searchTerm (str): The word to type into the search box\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            data.searchbar.send_keys(searchTerm)\n",
    "            data.searchbar.send_keys(Keys.RETURN) # Return = Enter\n",
    "        except:\n",
    "            print(\"Exception: No search term input\")\n",
    "    \n",
    "    @exceptionHandling\n",
    "    def findSearchbar(self, searchTerm) -> None:\n",
    "        '''\n",
    "        This function finds the searchbar and calls the searchbarTextAndClick() function with the searchTerm parameter.\n",
    "\n",
    "        Args: \n",
    "            searchTerm (str): The word passed to the searchbarTextAndClick() fucntion that types into the search box\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        data.searchbar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "        self.searchbarTextAndClick(searchTerm)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def home() -> None:\n",
    "        '''\n",
    "        Finds the title and clicks it.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "        title.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def findRecipeList(self) -> None:\n",
    "        '''\n",
    "        Finds the recipe tab and clicks it.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        data.button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "        data.button.click()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def acceptCookies() -> None:\n",
    "        '''\n",
    "        Finds the accept cookies button and clicks it.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        data.button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "        data.button.click()\n",
    "    \n",
    "    def getRecipes(self, url) -> None:\n",
    "        '''\n",
    "        Calls the functions to find the recipe container and puts all the recipes in a list.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The target website that contains all the recipe search results\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.getRecipeContainer()\n",
    "        self.makeRecipeList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeContainer() -> None:\n",
    "        '''\n",
    "        This function finds the recipe container\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='index-item-container']/div/div[2]/ul\"))) \n",
    "\n",
    "    def makeRecipeList() -> None:\n",
    "        '''\n",
    "        This function finds the individual recipe page link and stores it in a list\n",
    "\n",
    "        This function finds an individual recipes link by identifying the container \n",
    "        with all the recipes, then loops through that contain to find the individual \n",
    "        recipes and takes the url for that recipe and stores it in a list.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.articles = data.container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        for i in data.articles:\n",
    "            data.tag = i.find_element(By.TAG_NAME, 'a')\n",
    "            data.recipeLinks.append(data.tag.get_attribute('href'))\n",
    "\n",
    "    def getPageURL() -> None:\n",
    "        '''\n",
    "        Returns the current page url.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.currentURL =  driver.current_url\n",
    "\n",
    "    def getAllRecipePages(self, url) -> None:\n",
    "        '''\n",
    "        Calls the functions to navigate to each recipe page by modifying the current url and stores them in a list.\n",
    "        \n",
    "        Args:\n",
    "            url (str): The target website that contains all the recipe search results\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.getTotalPages()\n",
    "        self.getSearchList()\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getTotalPages() -> None:\n",
    "        '''\n",
    "        This function counts the total number of page results.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        #totalPages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "        data.totalPages = [1, 2, 3] #temp to shorten runtime\n",
    "\n",
    "    def getSearchList() -> None:\n",
    "        '''\n",
    "        This function retrieves the url of each search result by modifying the url.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        for i in data.totalPages:\n",
    "            data.currentURL = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = data.currentURL + url_change\n",
    "            data.pages.append(next_page)\n",
    "\n",
    "    def getUniqueID(self, url) -> None:\n",
    "        '''\n",
    "        This function creates a uuid for each recipe by modifying  a url as a perameter. \n",
    "\n",
    "        Args: \n",
    "            url (str): The recipe page url\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "        return ids\n",
    "\n",
    "    @scrapeHandling(data.name)\n",
    "    def scrapeName() -> None:\n",
    "        '''\n",
    "        This function scrapes the name of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "\n",
    "    @scrapeHandling(data.recipeTags)\n",
    "    def scrapeTags() -> None:\n",
    "        '''\n",
    "        This function scrapes the tags of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.recipeTags = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "\n",
    "    @scrapeHandling(data.description)\n",
    "    def scrapeDescription() -> None:\n",
    "        '''\n",
    "        This function scrapes the description of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.description = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "\n",
    "    @scrapeHandling(data.timeTotal)\n",
    "    def scrapeTotalTime() -> None:\n",
    "        '''\n",
    "        This function scrapes the total cook time of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.timeTotal = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "\n",
    "    @scrapeHandling(data.timePrep)\n",
    "    def scrapePrepTime() -> None:\n",
    "        '''\n",
    "        This function scrapes the prep time of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.timePrep = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "\n",
    "    @scrapeHandling(data.timeCook)\n",
    "    def scrapeCookTime() -> None:\n",
    "        '''\n",
    "        This function scrapes the cook time of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.timeCook = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "\n",
    "    @scrapeHandling(data.allergens)\n",
    "    def scrapeAllergens() -> None:\n",
    "        '''\n",
    "        This function scrapes the allergens of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        data.allergens = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "\n",
    "    @scrapeHandling(data.alternatives)\n",
    "    def scrapeAlternatives() -> None:\n",
    "        '''\n",
    "        This function scrapes the alternative ingrediants of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.alternatives = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "\n",
    "    @scrapeHandling(data.freeFrom)\n",
    "    def scrapeFreeFrom() -> None:\n",
    "        '''\n",
    "        This function scrapes what the recipe is free from. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.freeFrom = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text \n",
    "\n",
    "    @scrapeHandling(data.ingredients)\n",
    "    def scrapeIngredients() -> None:\n",
    "        '''\n",
    "        This function scrapes the recipe ingredients. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.ingredients = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "\n",
    "    @scrapeHandling(data.instructions)\n",
    "    def scrapeInstructions() -> None:\n",
    "        '''\n",
    "        This function scrapes the instructions for the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.instructions = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "\n",
    "    @scrapeHandling(data.notes)\n",
    "    def scrapeNotes() -> None:\n",
    "        '''\n",
    "        This function scrapes the notes from the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.notes = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "\n",
    "    @scrapeHandling(data.storage)\n",
    "    def scrapeStorage() -> None:\n",
    "        '''\n",
    "        This function scrapes the storage instructions of the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.storage = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "\n",
    "    @scrapeHandling(data.mainPhoto)\n",
    "    def scrapeMainPhoto() -> None:\n",
    "        '''\n",
    "        This function scrapes the main image from the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.mainPhoto = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "\n",
    "\n",
    "    @exceptionHandling\n",
    "    def scrapeImages() -> None:\n",
    "        '''\n",
    "        This function scrapes the other images from the recipe. Exception handling is done with a decorator\n",
    "\n",
    "        This function finds the image container then puts its children into a list. A limit is set based on the number of images found for later use. Finally the list is \n",
    "        iterated to get each images url link to create a list of image links\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        imageContainer = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        imageList = imageContainer.find_elements(By.XPATH, 'img') # Find the children\n",
    "        data.imageScrapeLimiter = len(imageList)\n",
    "\n",
    "        for i in imageList:\n",
    "            link = i.get_attribute('src')\n",
    "            data.imageLinks.append(link)\n",
    "\n",
    "    @exceptionHandling\n",
    "    def getRecipeDetails(self, url) -> None:\n",
    "        '''\n",
    "        This function calls the scrape functions\n",
    "\n",
    "        This function navigates to a recipe page and calls all the scrape functions to collect \n",
    "        the data from the page. It the calls the function that stores all the data in a dictionary \n",
    "        and calls the function that writes that dictionary to a json file\n",
    "\n",
    "        Args:\n",
    "            url (str): The recipe page url\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        self.getURL(self, url)\n",
    "\n",
    "        self.scrapeName()  \n",
    "        self.scrapeTags()\n",
    "        self.scrapeDescription()\n",
    "        self.scrapeTotalTime()\n",
    "        self.scrapePrepTime()\n",
    "        self.scrapeCookTime()\n",
    "        self.scrapeAllergens()\n",
    "        self.scrapeAlternatives()\n",
    "        self.scrapeFreeFrom()\n",
    "        self.scrapeIngredients()\n",
    "        self.scrapeInstructions()\n",
    "        self.scrapeNotes()\n",
    "        self.scrapeStorage()\n",
    "        self.scrapeMainPhoto()\n",
    "        self.scrapeImages()\n",
    "\n",
    "        self.storeDetails(self, url)\n",
    "        self.jsonFile(self)\n",
    "\n",
    "    def storeDetails(self, url) -> None:\n",
    "        '''\n",
    "        This function updates the data dictionarl with all the scraped information\n",
    "\n",
    "        Args: \n",
    "            url (str): The recipe url to make a unique ID\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        data.recipeDetails = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        data.recipeDetails['ID'].append(self.getUniqueID(self, url))\n",
    "        data.recipeDetails['Name'].append(data.name)\n",
    "        data.recipeDetails['Photo'].append(data.mainPhoto)\n",
    "        data.recipeDetails['Tags'].append(data.recipeTags)\n",
    "        data.recipeDetails['Description'].append(data.description)\n",
    "        data.recipeDetails['Total Time'].append(data.timeTotal)\n",
    "        data.recipeDetails['Prep Time'].append(data.timePrep)\n",
    "        data.recipeDetails['Cook Time'].append(data.timeCook)\n",
    "        data.recipeDetails['Allergens'].append(data.allergens)\n",
    "        data.recipeDetails['Swaps'].append(data.alternatives)\n",
    "        data.recipeDetails['Free From'].append(data.freeFrom)\n",
    "        data.recipeDetails['Ingredients'].append(data.ingredients)\n",
    "        data.recipeDetails['Directions'].append(data.instructions)\n",
    "        data.recipeDetails['Notes'].append(data.notes)\n",
    "        data.recipeDetails['Storage'].append(data.storage)\n",
    "        data.recipeDetails['Images'].append(data.imageLinks)\n",
    "\n",
    "    def jsonFile(self) -> None:\n",
    "        '''This function creates a folder for the json file to be stored in\n",
    "        \n",
    "        This function creates a folder called 'raw_data' in the path for the \n",
    "        json file to be saved in. Uses a try except catch as it will throw an \n",
    "        error if the folder already exists.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.makeRaw_DataFolder()\n",
    "\n",
    "        # Deals with TypeError: Object of type UUID is not JSON serializable by encoding the UUID\n",
    "        JSONEncoder_olddefault = JSONEncoder.default\n",
    "        def JSONEncoder_newdefault(self, o):\n",
    "            if isinstance(o, UUID): return str(o)\n",
    "            return JSONEncoder_olddefault(self, o)\n",
    "        JSONEncoder.default = JSONEncoder_newdefault\n",
    "\n",
    "        self.jsonDump()\n",
    "\n",
    "    @folderAlreadyExists(\"raw_data\")\n",
    "    def makeRaw_DataFolder():\n",
    "        '''\n",
    "        This function creates a folder.\n",
    "        \n",
    "        This function creates a folder for the json files to be stored in\n",
    "        Throws an exception if the folder already exists which is handeled \n",
    "        with a decorator.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.dataDirectory = \"raw_data\"\n",
    "        parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "        path = os.path.join(parent_dir, data.dataDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.dataDirectory)\n",
    "    \n",
    "    def jsonDump() -> None:\n",
    "        '''This function writes the dictionary data to a json file\n",
    "        \n",
    "        This function stores data by writing the 'recipe_details' dictionary to a JSON file called 'data.json' in the folder just created\n",
    "        The dicrionary is converted to a string using str() to deal with 'TypeError: Object of type WebElement is not JSON serializable\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        with open(os.path.join('raw_data', 'data.json'), 'w') as json_file:\n",
    "            json.dump(str(data.recipeDetails), json_file)\n",
    "\n",
    "    def downloadImage(self, url) -> None:\n",
    "        '''\n",
    "        This function creates a folder.\n",
    "        \n",
    "        This function calls the function that creates a folder called 'images' \n",
    "        Then calls the function that creates a folder named after the recipes name \n",
    "        Adds User-Agent Headers in a try/catch exeption handler to bypass 403 error\n",
    "        Downloads the image into the folder of that recipe name\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        self.makeImagesFolder()\n",
    "        self.makeRecipeFolder()\n",
    "\n",
    "        try:\n",
    "            # Adds headers to resolve 403 Fobidden Error\n",
    "            opener=urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "            path = os.path.join(data.recipeDirectory, data.imageFileName + '.jpg')\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        except:\n",
    "            print(\"Error Downloading Images\")         \n",
    "\n",
    "    @folderAlreadyExists(\"Images\")\n",
    "    def makeImagesFolder() -> None:\n",
    "        '''\n",
    "        This function makes a folder.\n",
    "\n",
    "        This function Makes a folder called images for the recipe images to be stored in.\n",
    "        Uses a try except catch in a decorator as it will throw an error if the folders already exists.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.imageDirectory = \"images\"\n",
    "        path = os.path.join(data.parentDirectory, data.imageDirectory)\n",
    "        os.mkdir(path)\n",
    "\n",
    "    @folderAlreadyExists(\"Recipe\")\n",
    "    def makeRecipeFolder() -> None:\n",
    "        '''\n",
    "        This function makes a folder.\n",
    "\n",
    "        This function Makes a folder named after the recipe for the images to be stored in.\n",
    "        Uses a try except catch in a decorator as it will throw an error if the folders already exists.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "        \n",
    "        data.recipeDirectory = \"images/\" + data.name\n",
    "        path = os.path.join(data.parentDirectory, data.recipeDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.recipeDirectory)\n",
    "\n",
    "    def makeImage(self, url) -> None:\n",
    "        '''\n",
    "        This function makes a file name for the image and downloads it.\n",
    "        \n",
    "        This function retrieves the ID of each image using 'getRecipeDetails().\n",
    "        Removes all unecissary elements from the ID string to create a file name.\n",
    "        Pass the file name to 'downloadImages() to create a file.\n",
    "\n",
    "        Args:\n",
    "            url (str): The recipe url to scrape information from\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.getRecipeDetails(self, url)\n",
    "\n",
    "        for i in data.recipeDetails['Images']:\n",
    "\n",
    "            for j in i:\n",
    "                data.imageFileName = data.name + \" \" + str(data.count) + \".jpg\"\n",
    "                self.downloadImage(self, j)\n",
    "\n",
    "                if data.count < data.imageScrapeLimiter:\n",
    "                    data.count = data.count + 1\n",
    "                else:\n",
    "                    data.count = 0\n",
    "\n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons', 5)\n",
    "\n",
    "# IDEALS ---------------------------------------------------------------------------------------------------------------\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# make a separate main image\n",
    "# counts how many recipes there are on the site\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# replace all XPaths with written XPaths\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument\n",
    "# seperate website specific methods from general functioning in a class\n",
    "# make sure all code works with any website so is reusable and genralisable\n",
    "# use the unique id (page url) to stop scraping recipes it has already scraped \n",
    "# have a wait for element function that takes a xpath and a perameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for testing directories\n",
    "import requests # for testing website response\n",
    "import unittest\n",
    "import uuid # for testing the recipe unique identifyer\n",
    "from scraper import scraper\n",
    "\n",
    "class scraperTestCase(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls): # Runs at the begining of the file\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls): # Runs at the end of the file\n",
    "        pass\n",
    "\n",
    "    def setUp(self): # Runs before every test\n",
    "        self.bot1 = scraper() \n",
    "        self.recipe = 'harissa-spiced-beans-898-0.jpg'\n",
    "        self.directory = 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline'\n",
    "        self.friendlyID = 'harissa-spiced-beans-898'\n",
    "        self.systemID = uuid.uuid4()\n",
    "        self.dictionary = {\"ID\": []}\n",
    "        self.number = str(3)\n",
    "        self.recipeName = 'Harissa Spiced Beans'\n",
    "\n",
    "        self.folderName1 = 'images'\n",
    "        self.folderName2 = 'raw_data'\n",
    "        self.imagePath = os.path.join(self.directory, self.folderName1)\n",
    "        self.recipePath = os.path.join(self.directory, self.folderName1)\n",
    "        self.dataPath = os.path.join(self.directory, self.folderName2)\n",
    "        #self.handle = open(\"data.json\", \"r\") # Dont forget to test the json file\n",
    "\n",
    "    def tearDown(self): # Runs at the end of every test\n",
    "        del self.bot1\n",
    "    \n",
    "    def test_dataClass(self):\n",
    "        pass\n",
    "    \n",
    "    def test_decoratorClass(self):\n",
    "        pass\n",
    "\n",
    "    def test_exceptionHandling(self):\n",
    "        pass\n",
    "\n",
    "    def test_run(self):\n",
    "        pass\n",
    "\n",
    "    def test_cycleRecipeLinks(self):\n",
    "        pass\n",
    "\n",
    "    def test_getURL(self):\n",
    "        print(\"test_getURL\")\n",
    "        response = requests.get('https://www.pickuplimes.com/')\n",
    "\n",
    "        if response.ok:\n",
    "            print(\"Website Found\")\n",
    "            return response.text\n",
    "        else:\n",
    "            print(\"!Website Not Found!\")\n",
    "            return 'Bad Response'\n",
    "\n",
    "    def test_getTitle(self):\n",
    "        pass\n",
    "\n",
    "    def test_closeSession(self):\n",
    "        pass\n",
    "\n",
    "    def test_getSourceCode(self):\n",
    "        pass\n",
    "\n",
    "    def test_search(self):\n",
    "        pass\n",
    "\n",
    "    def test_searchbarTextAndClick(self):\n",
    "        pass\n",
    "\n",
    "    def test_findSearchbar(self):\n",
    "        pass\n",
    "\n",
    "    def test_home(self):\n",
    "        pass\n",
    "\n",
    "    def test_findRecipeList(self):\n",
    "        pass\n",
    "\n",
    "    def test_acceptCookies(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipes(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipeContainer(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeRecipeList(self):\n",
    "        pass\n",
    "\n",
    "    def test_getPageURL(self):\n",
    "        pass\n",
    "\n",
    "    def test_getAllRecipePages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getTotalPages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getSearchList(self):\n",
    "        pass\n",
    "\n",
    "    def test_getUniqueID(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeName(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeTags(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeDescription(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeTotalTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapePrepTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeCookTime(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeAllergens(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeAlternatives(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeFreeFrom(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeIngredients(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeInstructions(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeInstructions(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeNotes(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeStorage(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeMainPhoto(self):\n",
    "        pass\n",
    "\n",
    "    def test_scrapeImages(self):\n",
    "        pass\n",
    "\n",
    "    def test_getRecipeDetails(self):\n",
    "        pass\n",
    "\n",
    "    def test_storeDetails(self):\n",
    "        pass\n",
    "\n",
    "    def test_jsonFile(self):\n",
    "        pass\n",
    "\n",
    "    def test_makeRaw_DataFolder(self):\n",
    "        print('test_makeRaw_DataFolder')\n",
    "\n",
    "        # Check directory path \n",
    "        self.assertEqual(self.dataPath, 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline/raw_data')\n",
    "\n",
    "        # Check file name\n",
    "        self.assertEqual(os.path.join(self.recipePath, self.recipe), '')\n",
    "\n",
    "        data.dataDirectory = \"raw_data\"\n",
    "        \n",
    "        '''\n",
    "        path = os.path.join(parent_dir, data.dataDirectory)\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory '% s' created\" % data.dataDirectory)\n",
    "        '''\n",
    "\n",
    "        # UNFINISHED\n",
    "    def jsonDump(self):\n",
    "        print('jsonDump')\n",
    "\n",
    "        # Check json file was created\n",
    "\n",
    "        # Check dictionary was written in json\n",
    "    \n",
    "    # UNFINISHED\n",
    "    def test_downloadImage(self):\n",
    "        print('test_downloadImage')\n",
    "\n",
    "        # Check directory path\n",
    "        self.assertEqual(self.recipePath, 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\\images')\n",
    "\n",
    "        # Check image name\n",
    "        self.assertEqual(self.recipeName, 'Harissa Spiced Beans') \n",
    "\n",
    "        # Check image was downloaded\n",
    "\n",
    "    # UNFINISHED\n",
    "    def test_makeImagesFolder(self):\n",
    "        print('test_makeImagesFolder')       \n",
    "\n",
    "        # Check directory is correct\n",
    "        self.assertEqual(self.imagePath, 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\\images') \n",
    "\n",
    "        # Check folder was created\n",
    "\n",
    "    def test_makeRecipeFolder(self):\n",
    "        print('test_makeRecipeFolder')\n",
    "\n",
    "        # Check edited friendlyID\n",
    "        self.assertEqual(self.recipe.replace(\".jpg\", \"\").replace(\"0\", \"\"), 'harissa-spiced-beans-898-')\n",
    "\n",
    "        # Check directory\n",
    "        self.assertEqual(self.recipePath, 'C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\\images')\n",
    "\n",
    "    def test_makeImage(self):\n",
    "        print(\"test_makeImage\")\n",
    "\n",
    "        self.dictionary['ID'].append(self.friendlyID)\n",
    "        self.dictionary['ID'].append(self.systemID)\n",
    "\n",
    "        # Check the dictionary contains the correct IDs\n",
    "        self.assertEqual(self.dictionary['ID'][0], self.friendlyID)\n",
    "        self.assertAlmostEqual(self.dictionary['ID'][1], self.systemID)\n",
    "\n",
    "        # Check it removes all unnecessary bits from the string\n",
    "        editedID = (self.dictionary['ID'][0])\n",
    "        editedID = editedID.title()\n",
    "        editedID = editedID.replace(\"-\", \" \")\n",
    "        for i in editedID:\n",
    "            if i.isdigit():\n",
    "                editedID = editedID.replace(i , \"\")\n",
    "\n",
    "        # Check the finished string is correct\n",
    "        name = editedID + self.number + \".jpg\"\n",
    "        self.assertEqual(name, editedID + self.number + \".jpg\")     \n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    test_scraper() \n",
    "#    print(\"Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "flights_df = pd.read_csv(\"flights.txt\", sep=\"|\") # Make sure flights.txt is in the same directory\n",
    "flights_df.head(5) # Returns first 5 rows\n",
    "#print(flights_df) # Displays the database\n",
    "#print(flights_df.dtypes) # Displays the variable types\n",
    "\n",
    "# DISTANCE\n",
    "print(flights_df['DISTANCE'].sum())\n",
    "\n",
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
