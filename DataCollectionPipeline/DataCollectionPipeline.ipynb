{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pickuplimes.com/recipe/\n",
      "Exception: Timeout: Didnt Find Free-From\n",
      "Exception: Timeout: Didnt Find Storage\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Exception: Timeout: Didnt Find Cook-Time\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg', 'https://cdn.pickuplimes.com/cache/f4/24/f424d7f92506b5066cf40f13a518ae7d.jpg', 'https://cdn.pickuplimes.com/cache/dd/cb/ddcbbb73e0196023259964d912ee7931.jpg', 'https://cdn.pickuplimes.com/cache/51/5b/515bfb4ca93bd664a1e1f40db61eacfe.jpg', 'https://cdn.pickuplimes.com/cache/2c/c5/2cc5fd6be511410d5da377e18e864a23.jpg', 'https://cdn.pickuplimes.com/cache/a2/58/a25839bd84a540d14d08a0ea62d83b23.jpg', 'https://cdn.pickuplimes.com/cache/20/07/20073e41619b9fb9854f38776f1d1892.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Exception: Timeout: Didnt Find Storage\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg', 'https://cdn.pickuplimes.com/cache/f4/24/f424d7f92506b5066cf40f13a518ae7d.jpg', 'https://cdn.pickuplimes.com/cache/dd/cb/ddcbbb73e0196023259964d912ee7931.jpg', 'https://cdn.pickuplimes.com/cache/51/5b/515bfb4ca93bd664a1e1f40db61eacfe.jpg', 'https://cdn.pickuplimes.com/cache/2c/c5/2cc5fd6be511410d5da377e18e864a23.jpg', 'https://cdn.pickuplimes.com/cache/a2/58/a25839bd84a540d14d08a0ea62d83b23.jpg', 'https://cdn.pickuplimes.com/cache/20/07/20073e41619b9fb9854f38776f1d1892.jpg', 'https://cdn.pickuplimes.com/cache/08/60/0860bc1cc613fc27c82f9f839b20dc9c.jpg', 'https://cdn.pickuplimes.com/cache/5a/64/5a644d3c8db947104a092f9cdf1d9b32.jpg', 'https://cdn.pickuplimes.com/cache/86/ec/86ec676d3ad07a318c0ca513fe64fc03.jpg', 'https://cdn.pickuplimes.com/cache/c5/86/c5867e1984007baf444f521b18367bf0.jpg', 'https://cdn.pickuplimes.com/cache/e5/5c/e55caf83fec686cccc6821cd7064a418.jpg', 'https://cdn.pickuplimes.com/cache/87/a4/87a495b26b50078edebd042d8b368b19.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Exception: Timeout: Didnt Find Storage\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg', 'https://cdn.pickuplimes.com/cache/f4/24/f424d7f92506b5066cf40f13a518ae7d.jpg', 'https://cdn.pickuplimes.com/cache/dd/cb/ddcbbb73e0196023259964d912ee7931.jpg', 'https://cdn.pickuplimes.com/cache/51/5b/515bfb4ca93bd664a1e1f40db61eacfe.jpg', 'https://cdn.pickuplimes.com/cache/2c/c5/2cc5fd6be511410d5da377e18e864a23.jpg', 'https://cdn.pickuplimes.com/cache/a2/58/a25839bd84a540d14d08a0ea62d83b23.jpg', 'https://cdn.pickuplimes.com/cache/20/07/20073e41619b9fb9854f38776f1d1892.jpg', 'https://cdn.pickuplimes.com/cache/08/60/0860bc1cc613fc27c82f9f839b20dc9c.jpg', 'https://cdn.pickuplimes.com/cache/5a/64/5a644d3c8db947104a092f9cdf1d9b32.jpg', 'https://cdn.pickuplimes.com/cache/86/ec/86ec676d3ad07a318c0ca513fe64fc03.jpg', 'https://cdn.pickuplimes.com/cache/c5/86/c5867e1984007baf444f521b18367bf0.jpg', 'https://cdn.pickuplimes.com/cache/e5/5c/e55caf83fec686cccc6821cd7064a418.jpg', 'https://cdn.pickuplimes.com/cache/87/a4/87a495b26b50078edebd042d8b368b19.jpg', 'https://cdn.pickuplimes.com/cache/2f/12/2f1270f1397ce8507385378da2a20dec.jpg', 'https://cdn.pickuplimes.com/cache/de/41/de415573620463b7d336e87a23a9a2e7.jpg', 'https://cdn.pickuplimes.com/cache/27/8f/278f4a7ccfd029b85739b89dd94fa391.jpg', 'https://cdn.pickuplimes.com/cache/d8/94/d894952b254e7cfad68684763ad72eb0.jpg', 'https://cdn.pickuplimes.com/cache/3f/81/3f81be46dad5cf1fc9715478cef9f79e.jpg', 'https://cdn.pickuplimes.com/cache/e7/c2/e7c2deb34366e1b889f8dfc93f9291df.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg', 'https://cdn.pickuplimes.com/cache/f4/24/f424d7f92506b5066cf40f13a518ae7d.jpg', 'https://cdn.pickuplimes.com/cache/dd/cb/ddcbbb73e0196023259964d912ee7931.jpg', 'https://cdn.pickuplimes.com/cache/51/5b/515bfb4ca93bd664a1e1f40db61eacfe.jpg', 'https://cdn.pickuplimes.com/cache/2c/c5/2cc5fd6be511410d5da377e18e864a23.jpg', 'https://cdn.pickuplimes.com/cache/a2/58/a25839bd84a540d14d08a0ea62d83b23.jpg', 'https://cdn.pickuplimes.com/cache/20/07/20073e41619b9fb9854f38776f1d1892.jpg', 'https://cdn.pickuplimes.com/cache/08/60/0860bc1cc613fc27c82f9f839b20dc9c.jpg', 'https://cdn.pickuplimes.com/cache/5a/64/5a644d3c8db947104a092f9cdf1d9b32.jpg', 'https://cdn.pickuplimes.com/cache/86/ec/86ec676d3ad07a318c0ca513fe64fc03.jpg', 'https://cdn.pickuplimes.com/cache/c5/86/c5867e1984007baf444f521b18367bf0.jpg', 'https://cdn.pickuplimes.com/cache/e5/5c/e55caf83fec686cccc6821cd7064a418.jpg', 'https://cdn.pickuplimes.com/cache/87/a4/87a495b26b50078edebd042d8b368b19.jpg', 'https://cdn.pickuplimes.com/cache/2f/12/2f1270f1397ce8507385378da2a20dec.jpg', 'https://cdn.pickuplimes.com/cache/de/41/de415573620463b7d336e87a23a9a2e7.jpg', 'https://cdn.pickuplimes.com/cache/27/8f/278f4a7ccfd029b85739b89dd94fa391.jpg', 'https://cdn.pickuplimes.com/cache/d8/94/d894952b254e7cfad68684763ad72eb0.jpg', 'https://cdn.pickuplimes.com/cache/3f/81/3f81be46dad5cf1fc9715478cef9f79e.jpg', 'https://cdn.pickuplimes.com/cache/e7/c2/e7c2deb34366e1b889f8dfc93f9291df.jpg', 'https://cdn.pickuplimes.com/cache/58/7a/587a8efb4a438c22521a8b2f32d929b1.jpg', 'https://cdn.pickuplimes.com/cache/8b/12/8b12888665c15550794dd050ff23a8af.jpg', 'https://cdn.pickuplimes.com/cache/52/41/5241eeba22aa768f5036b01f09215414.jpg', 'https://cdn.pickuplimes.com/cache/dd/c9/ddc9b1940db9265034c9ff4f4ca84478.jpg', 'https://cdn.pickuplimes.com/cache/19/3e/193e01121667107bd9340264b434d0c4.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Exception: Timeout: Didnt Find Free-From\n",
      "Exception: Timeout: Didnt Find Storage\n",
      "['https://cdn.pickuplimes.com/cache/43/28/43283acc58c3570e843c70e24ab41a89.jpg', 'https://cdn.pickuplimes.com/cache/ca/07/ca075a40670c0aa5dc8cc83d6c351fa5.jpg', 'https://cdn.pickuplimes.com/cache/db/7e/db7e742548aee15f25546b954f47588f.jpg', 'https://cdn.pickuplimes.com/cache/97/62/97623174f4d7a48cfb170e6d2eccda43.jpg', 'https://cdn.pickuplimes.com/cache/ee/83/ee8389bca0e9eaabafcba10cfcde88bf.jpg', 'https://cdn.pickuplimes.com/cache/61/23/612392d4353f5bdb4ed16806509af2bc.jpg', 'https://cdn.pickuplimes.com/cache/f4/24/f424d7f92506b5066cf40f13a518ae7d.jpg', 'https://cdn.pickuplimes.com/cache/dd/cb/ddcbbb73e0196023259964d912ee7931.jpg', 'https://cdn.pickuplimes.com/cache/51/5b/515bfb4ca93bd664a1e1f40db61eacfe.jpg', 'https://cdn.pickuplimes.com/cache/2c/c5/2cc5fd6be511410d5da377e18e864a23.jpg', 'https://cdn.pickuplimes.com/cache/a2/58/a25839bd84a540d14d08a0ea62d83b23.jpg', 'https://cdn.pickuplimes.com/cache/20/07/20073e41619b9fb9854f38776f1d1892.jpg', 'https://cdn.pickuplimes.com/cache/08/60/0860bc1cc613fc27c82f9f839b20dc9c.jpg', 'https://cdn.pickuplimes.com/cache/5a/64/5a644d3c8db947104a092f9cdf1d9b32.jpg', 'https://cdn.pickuplimes.com/cache/86/ec/86ec676d3ad07a318c0ca513fe64fc03.jpg', 'https://cdn.pickuplimes.com/cache/c5/86/c5867e1984007baf444f521b18367bf0.jpg', 'https://cdn.pickuplimes.com/cache/e5/5c/e55caf83fec686cccc6821cd7064a418.jpg', 'https://cdn.pickuplimes.com/cache/87/a4/87a495b26b50078edebd042d8b368b19.jpg', 'https://cdn.pickuplimes.com/cache/2f/12/2f1270f1397ce8507385378da2a20dec.jpg', 'https://cdn.pickuplimes.com/cache/de/41/de415573620463b7d336e87a23a9a2e7.jpg', 'https://cdn.pickuplimes.com/cache/27/8f/278f4a7ccfd029b85739b89dd94fa391.jpg', 'https://cdn.pickuplimes.com/cache/d8/94/d894952b254e7cfad68684763ad72eb0.jpg', 'https://cdn.pickuplimes.com/cache/3f/81/3f81be46dad5cf1fc9715478cef9f79e.jpg', 'https://cdn.pickuplimes.com/cache/e7/c2/e7c2deb34366e1b889f8dfc93f9291df.jpg', 'https://cdn.pickuplimes.com/cache/58/7a/587a8efb4a438c22521a8b2f32d929b1.jpg', 'https://cdn.pickuplimes.com/cache/8b/12/8b12888665c15550794dd050ff23a8af.jpg', 'https://cdn.pickuplimes.com/cache/52/41/5241eeba22aa768f5036b01f09215414.jpg', 'https://cdn.pickuplimes.com/cache/dd/c9/ddc9b1940db9265034c9ff4f4ca84478.jpg', 'https://cdn.pickuplimes.com/cache/19/3e/193e01121667107bd9340264b434d0c4.jpg', 'https://cdn.pickuplimes.com/cache/18/45/18454bf32f95f3665857904309d577de.jpg', 'https://cdn.pickuplimes.com/cache/98/ad/98ad3b78159d2f768e2bfa3acc51b0e5.jpg', 'https://cdn.pickuplimes.com/cache/0c/f2/0cf2476f2493ce46675acec9b3944cbb.jpg', 'https://cdn.pickuplimes.com/cache/2b/0d/2b0d51f5d6dfeaf6945545fc06b1372e.jpg', 'https://cdn.pickuplimes.com/cache/10/ab/10abe3ede08499c8fe46061591b9e3ce.jpg', 'https://cdn.pickuplimes.com/cache/ed/4b/ed4bd2c0ec9978eebfac436ba20cb421.jpg']\n",
      "Root Folder 'raw_data' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Error Downloading Image\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n",
      "Root Folder 'images' Already Exists\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "\n",
    "from uuid import UUID\n",
    "from json import JSONEncoder\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class data:\n",
    "    articles = []\n",
    "    currentURL = \"\"\n",
    "    image_links = []\n",
    "    pages = []\n",
    "    recipe_details = {}\n",
    "    recipeLinks = []\n",
    "\n",
    "class scraper:\n",
    "    def intitialize(self, url, search_term, delay):\n",
    "        global_ids = scraper.getUniqueID(scraper, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "        \n",
    "        self.getURL(url)\n",
    "        #self.getTitle()\n",
    "        #self.acceptCookies()\n",
    "        #self.getAllRecipePages(self) # Could be private?\n",
    "        #self.getSourceCode()\n",
    "        #self.search(search_term)\n",
    "        #time.sleep(3)\n",
    "        #self.home()\n",
    "        #self.findRecipeList() # Could be private?\n",
    "        #self.getRecipes(self, 'https://www.pickuplimes.com/recipe/?page=5')\n",
    "        #self.getPageURL()\n",
    "        #self.getUniqueID()\n",
    "        #self.getRecipeDetails(self)\n",
    "        #self.jsonFile() # Could be private?\n",
    "        #self.downloadImage('/html/body/img', 'nameForImage') # Could be private?\n",
    "        #self.getRecipeDetails(self)\n",
    "        self.testFunction(self, 'https://www.pickuplimes.com/recipe/spicy-garlic-wok-noodles-213')\n",
    "\n",
    "        self.closeSession()\n",
    "\n",
    "    def testFunction(self, url):\n",
    "        data.currentURL = self.findRecipeList(self)\n",
    "        print(data.currentURL)\n",
    "\n",
    "        self.getAllRecipePages(self, data.currentURL)\n",
    "        #for i in data.pages:\n",
    "        self.getRecipes(self, data.currentURL)\n",
    "        for i in data.recipeLinks:\n",
    "            #self.getRecipeDetails(self, i)\n",
    "            self.makeImageFilename(self, i)\n",
    "\n",
    "\n",
    "        #for i in data.pages:\n",
    "            #self.makeImageFilename(self, i)\n",
    "\n",
    "    def getURL(url):\n",
    "        '''Navigates to a website using a url passed as a perameter.'''\n",
    "        driver.get(url) \n",
    "\n",
    "    def getTitle():\n",
    "        '''Fetches the title and prints it to screen.'''\n",
    "        print(driver.title)\n",
    "\n",
    "    def closeSession():\n",
    "        '''Closes the driver after 3 seconds.'''\n",
    "        time.sleep(3)\n",
    "        driver.quit()\n",
    "\n",
    "    def getSourceCode():\n",
    "        '''Fetches source code for the page.'''\n",
    "        print(driver.page_source)\n",
    "\n",
    "    def search(search_term):\n",
    "        '''Finds search bar, types in the search term which it takes as a perameter and clicks to navigate to the next page.'''\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-searchbar-btn')))\n",
    "            button.click()\n",
    "            try:\n",
    "                search_bar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.NAME, \"sb\")))\n",
    "                try:\n",
    "                    search_bar.send_keys(search_term)\n",
    "                    search_bar.send_keys(Keys.RETURN) # Return = Enter\n",
    "                except:\n",
    "                    print(\"Exception: No search term input\")\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: No search bar found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Search bar\")\n",
    "\n",
    "    def home():\n",
    "        '''Finds the title and clicks it.'''\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'nav-image')))\n",
    "            title.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Title Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Title\")\n",
    "\n",
    "    def findRecipeList(self):\n",
    "        '''Finds the recipe tab and clicks it.'''\n",
    "        try:\n",
    "            button = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.LINK_TEXT, 'Recipes')))\n",
    "            button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Recipe List Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Recipe List\")\n",
    "\n",
    "        return self.getPageURL()\n",
    "\n",
    "    def acceptCookies():\n",
    "        '''Finds the accept cookies button and clicks it.'''\n",
    "        try:\n",
    "            cookie_button = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div[2]/div[2]')))\n",
    "            cookie_button.click()\n",
    "            print(\"Removed Cookies\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exeption: Didnt Find Cookie Button\")\n",
    "        except TimeoutException:\n",
    "            print(\"Timeout: Accept Cookie\")\n",
    "    \n",
    "    def getRecipes(self, url):\n",
    "        '''Finds the recipe container and puts all the recipes in a list.'''\n",
    "\n",
    "        try:\n",
    "            main = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, \"//*[@id='index-item-container']/div/div[2]/ul\"))) \n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Can't Find Recipe List\")\n",
    "        except TimeoutException: \n",
    "            print(\"Exception: Timeout: Can't Find Recipe List\")\n",
    "\n",
    "        data.articles = main.find_elements(By.TAG_NAME, 'li')\n",
    "        for i in data.articles:\n",
    "            tag = i.find_element(By.TAG_NAME, 'a')\n",
    "            data.recipeLinks.append(tag.get_attribute('href'))\n",
    "\n",
    "    def getPageURL():\n",
    "        '''Returns the current page url.'''\n",
    "        return driver.current_url\n",
    "\n",
    "    def getAllRecipePages(self, url):\n",
    "        '''Navigates to each recipe page by modifying the current url and stores them in a list.'''\n",
    "\n",
    "        try:\n",
    "            #total_pages = driver.find_element(By.CLASS_NAME, 'page-text') #actual\n",
    "            total_pages = [1, 2, 3, 4, 5] #temp to shorten runtime\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: Total Pages Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Couldn't Find Total Pages\")\n",
    "\n",
    "        for i in total_pages:\n",
    "            data.currentURL = driver.current_url\n",
    "            url_change = \"?page=\" + str(i)\n",
    "            next_page = data.currentURL + url_change\n",
    "            data.pages.append(next_page)\n",
    "\n",
    "    def getUniqueID(self, url):\n",
    "        '''Creates a uuid for each recipe taking a url as a perameter'''\n",
    "        \n",
    "        page_ID = url\n",
    "        just_ID = page_ID.replace(str(\"https://www.pickuplimes.com/recipe/\"), \"\")\n",
    "\n",
    "        ids = (just_ID, uuid.uuid4())\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def getRecipeDetails(self, url):\n",
    "        self.getURL(url)\n",
    "\n",
    "        try:\n",
    "            try:    \n",
    "                name = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/h1'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Name Not Found\")\n",
    "                name = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Name\")\n",
    "                name = \"N/A\"  \n",
    "\n",
    "            try:\n",
    "                tag = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"header-info-col\"]/div/header/a[1]/div/p'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Tag Not Found\")\n",
    "                tag = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Tag\")\n",
    "                tag = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                description = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"header-info-col\"]/div/header/span'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Description Not Found\")\n",
    "                description = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Description\")\n",
    "                description = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                time_total = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[2]'))).text  \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Total-Time Not Found\")\n",
    "                time_total = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Total-Time\")\n",
    "                time_total = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                time_prep = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[3]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Prep-Time Not Found\")\n",
    "                time_pre = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Prep-Time\")\n",
    "                time_pre = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                time_cook = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-info-container\"]/div[4]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Cook-Time Not Found\")\n",
    "                time_cook = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Cook-Time\")\n",
    "                time_cook = \"N/A\" \n",
    "\n",
    "            try:\n",
    "                allergens = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[1]/div'))).text \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Allergens Not Found\")\n",
    "                allergens = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Allergens\")\n",
    "                allergens = \"N/A\" \n",
    "\n",
    "            try: \n",
    "                swap = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[2]/div'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Swap Not Found\")\n",
    "                swap = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Swap\")\n",
    "                swap = \"N/A\" \n",
    "            \n",
    "            try:\n",
    "                free_from = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"allergen-info-container\"]/div[3]/div'))).text \n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Free-From Not Found\")\n",
    "                free_from = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Free-From\")\n",
    "                free_from = \"N/A\" \n",
    "\n",
    "            try:\n",
    "                ingredients = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[2]'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Ingredients Not Found\")\n",
    "                ingredients = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Ingredients\")\n",
    "                ingredients = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                directions = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ol'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Directions Not Found\")\n",
    "                directions = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Directions\")\n",
    "                directions = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                notes = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[1]/li'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Notes Not Found\")\n",
    "                notes = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Notes\")\n",
    "                notes = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                storage = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ingredient-direction-container\"]/div/div[4]/section/ul[2]/li'))).text\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Storage Not Found\")\n",
    "                storage = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Storage\")\n",
    "                storage = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                picture_main = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"main-image-container\"]/img')))\n",
    "            except NoSuchElementException:\n",
    "                print(\"Exception: Main Image Not Found\")\n",
    "                picture_main = \"N/A\"\n",
    "            except TimeoutException:\n",
    "                print(\"Exception: Timeout: Didnt Find Main Image\")\n",
    "                picture_main = \"N/A\"\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Exception: One Or More Data Entry Not Found\")\n",
    "        except TimeoutException:\n",
    "            print(\"Exception: Timeout: Didnt Find All Data Entries\")\n",
    "\n",
    "        image_container = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"recipe-video\"]/div[2]'))) # Find the container\n",
    "        image_list = image_container.find_elements(By.XPATH, 'img') # Find the children\n",
    "\n",
    "        for i in image_list:\n",
    "            link = i.get_attribute('src')\n",
    "            data.image_links.append(link)\n",
    "        \n",
    "        data.recipe_details = {'ID': [], 'Name': [], 'Photo': [],'Tags': [], 'Description': [], 'Total Time': [], 'Prep Time': [], 'Cook Time': [], 'Allergens': [], 'Swaps': [], 'Free From': [], 'Ingredients': [], 'Directions': [], 'Notes': [], 'Storage': [], 'Images': []}\n",
    "        data.recipe_details['ID'].append(self.getUniqueID(self, url))\n",
    "        data.recipe_details['Name'].append(name)\n",
    "        data.recipe_details['Photo'].append(picture_main)\n",
    "        data.recipe_details['Tags'].append(tag)\n",
    "        data.recipe_details['Description'].append(description)\n",
    "        data.recipe_details['Total Time'].append(time_total)\n",
    "        data.recipe_details['Prep Time'].append(time_prep)\n",
    "        data.recipe_details['Cook Time'].append(time_cook)\n",
    "        data.recipe_details['Allergens'].append(allergens)\n",
    "        data.recipe_details['Swaps'].append(swap)\n",
    "        data.recipe_details['Free From'].append(free_from)\n",
    "        data.recipe_details['Ingredients'].append(ingredients)\n",
    "        data.recipe_details['Directions'].append(directions)\n",
    "        data.recipe_details['Notes'].append(notes)\n",
    "        data.recipe_details['Storage'].append(storage)\n",
    "        data.recipe_details['Images'].append(data.image_links)\n",
    "        print(data.image_links)\n",
    "\n",
    "        self.jsonFile(self)\n",
    "\n",
    "    def jsonFile(self):\n",
    "        '''Creates a folder called 'raw_data' in the path for the json file to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folder already exists'''\n",
    "        try:\n",
    "            directory = \"raw_data\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Root Folder 'raw_data' Already Exists\")\n",
    "\n",
    "        '''Deals with TypeError: Object of type UUID is not JSON serializable by encoding the UUID'''\n",
    "        JSONEncoder_olddefault = JSONEncoder.default\n",
    "        def JSONEncoder_newdefault(self, o):\n",
    "            if isinstance(o, UUID): return str(o)\n",
    "            return JSONEncoder_olddefault(self, o)\n",
    "        JSONEncoder.default = JSONEncoder_newdefault\n",
    "\n",
    "        '''Stores data by writing the 'recipe_details' dictionary to a JSON file called 'data.json' in the folder just created\n",
    "        The dicrionary is converted to a string using str() to deal with 'TypeError: Object of type WebElement is not JSON serializable'''\n",
    "        with open(os.path.join('raw_data', 'data.json'), 'w') as json_file:\n",
    "            json.dump(str(data.recipe_details), json_file)\n",
    "\n",
    "    def downloadImage(url, recipeName):\n",
    "        '''Creates a folder called 'images' in the path for the image files to be saved in\n",
    "        Uses a try except catch as it will throw an error if the folder already exists\n",
    "        Adds User-Agent Headers to bypass 403 error\n",
    "        Downloads an image into the images folder'''\n",
    "        try:\n",
    "            directory = \"images\"\n",
    "            parent_dir = \"C:/Users/Millie/Documents/AiCore/AiCore/DataCollectionPipeline\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            os.mkdir(path)\n",
    "            print(\"Directory '% s' created\" % directory)\n",
    "        except:\n",
    "            print(\"Root Folder 'images' Already Exists\")\n",
    "        \n",
    "        try:\n",
    "            # Adds headers to resolve 403 Fobidden Error\n",
    "            opener=urllib.request.build_opener()\n",
    "            opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1941.0 Safari/537.36')]\n",
    "            urllib.request.install_opener(opener)\n",
    "\n",
    "            directory = \"images/\"\n",
    "            fileType = '.jpg'\n",
    "            fileName = directory + recipeName + fileType\n",
    "            image = urllib.request.urlretrieve(url, fileName)\n",
    "        except:\n",
    "            print(\"Error Downloading Image\")           \n",
    "\n",
    "    def makeImageFilename(self, url):\n",
    "        '''Retrieves the ID of each image using 'getRecipeDetails()\n",
    "        Removes all unecissary elements from the ID string to create a file name\n",
    "        Pass the file name to 'downloadImages() to create a file'''\n",
    "\n",
    "        self.getRecipeDetails(self, url)\n",
    "        for i in data.recipe_details['Images']:\n",
    "            for j in i:\n",
    "                IDtoName = str(data.recipe_details['ID']).split()\n",
    "                IDtoName1 = str(IDtoName[0]).replace(\"(\", \"\")\n",
    "                IDtoName2 = str(IDtoName1).replace(\"[\", \"\")\n",
    "                IDtoName3 = str(IDtoName2).replace(\",\", \"\")\n",
    "                IDtoName4 = str(IDtoName3).replace(\"'\", \"\")\n",
    "\n",
    "                self.downloadImage(j, IDtoName4)\n",
    "        \n",
    "scraper.intitialize(scraper, 'https://www.pickuplimes.com', 'lemons', 5)\n",
    "#scraper.testFunction(scraper)\n",
    "\n",
    "# IDEALS\n",
    "# store all recipe images in a list\n",
    "# link getTitle() and home()\n",
    "# link getPageURL() and getUniqueID()\n",
    "# get search results\n",
    "# get search results on more than the first page\n",
    "# make a separate main image\n",
    "# counts how many recipes there are\n",
    "# a for loop that automaticaly changes the xpath to get all the images for the recipe\n",
    "# bypass login\n",
    "# replace all XPaths with written XPatha\n",
    "# a method that makes a list containing all buttons and cycles through them looking for a link_text given as an argument\n",
    "# seperate website specific methods from general functioning\n",
    "# make sure all code works with any website so is reusable and genralisable"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f331584aba9fd139438438d44e9f0981e5b7ec53d275c2a7e5fdd51f9e359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataCollectionPipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
